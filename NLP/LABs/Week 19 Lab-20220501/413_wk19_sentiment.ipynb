{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcv86LYpnALt"
      },
      "source": [
        "# SCC.413 Applied Data Mining\n",
        "# Week 18\n",
        "# Sentiment Analysis\n",
        "\n",
        "The task here is to build your own classifier for predicting the sentiment of Tweets. Tweets are provided from [SemEval-2016 Task 4 (Subtask A)](http://alt.qcri.org/semeval2016/task4/).\n",
        "\n",
        "Using code and features from previous labs, build and evaluate a sentiment classifier, which classifies individual Tweets into `positive`, `negative` or `neutral`.\n",
        "\n",
        "Specialised feature sets could be:\n",
        "- Specific emoticons\n",
        "- Just adjectives\n",
        "- Words from a sentiment lexicon (e.g. see \"Opinion Lexicon\" from https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon).\n",
        "\n",
        "Below are imports and helper functions from previous labs. You should edit and add to these."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy"
      ],
      "metadata": {
        "id": "6YnSWkzPC3Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdQHOGponAL0"
      },
      "outputs": [],
      "source": [
        "import ftfy\n",
        "import nltk\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import Binarizer, StandardScaler\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join, splitext, split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVFSAeWpnAL3"
      },
      "source": [
        "For POS tagger, incase these haven't been previously downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgVLwvYGnAL4"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "ydCluoej2UY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save the folder we are working from as a variable for easy access. You may need to edit the path to match your own."
      ],
      "metadata": {
        "id": "trooi5ZMzSM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "working_folder = '/content/gdrive/MyDrive/413/wk19/'"
      ],
      "metadata": {
        "id": "c1YsiHLvzKeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code adds the working folder to the system path, so you can import Python files from this folder."
      ],
      "metadata": {
        "id": "ktoDdLMkBVMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(working_folder)"
      ],
      "metadata": {
        "id": "Cq_7TvOW34v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfNilWWenAL6"
      },
      "source": [
        "A couple of methods for showing classifier results (from 1st classification lab):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbTiKQy_nAL6"
      },
      "outputs": [],
      "source": [
        "def print_cv_scores_summary(name, scores):\n",
        "    print(\"{}: mean = {:.2f}%, sd = {:.2f}%, min = {:.2f}, max = {:.2f}\".format(name, scores.mean()*100, scores.std()*100, scores.min()*100, scores.max()*100))\n",
        "    \n",
        "def confusion_matrix_heatmap(cm, index):\n",
        "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
        "    dims = (10, 10)\n",
        "    fig, ax = plt.subplots(figsize=dims)\n",
        "    sns.heatmap(cmdf, annot=True, cmap=\"coolwarm\", center=0)\n",
        "    ax.set_ylabel('Actual')    \n",
        "    ax.set_xlabel('Predicted')\n",
        "    \n",
        "def confusion_matrix_percent_heatmap(cm, index):\n",
        "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
        "    percents = cmdf.div(cmdf.sum(axis=1), axis=0)*100\n",
        "    dims = (10, 10)\n",
        "    fig, ax = plt.subplots(figsize=dims)\n",
        "    sns.heatmap(percents, annot=True, cmap=\"coolwarm\", center=0, vmin=0, vmax=100)\n",
        "    ax.set_ylabel('Actual')    \n",
        "    ax.set_xlabel('Predicted')\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.set_ticks([0, 25, 50, 75, 100])\n",
        "    cbar.set_ticklabels(['0%', '25%', '50%', '75%', '100%'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ru9dS7nAL8"
      },
      "source": [
        "Our Document class and associated functions for processing text, similar to what you've seen in other labs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWdjwOUEnAL8"
      },
      "outputs": [],
      "source": [
        "hashtag_re = re.compile(r\"#\\w+\")\n",
        "mention_re = re.compile(r\"@\\w+\")\n",
        "url_re = re.compile(r\"(?:https?://)?(?:[-\\w]+\\.)+[a-zA-Z]{2,9}[-\\w/#~:;.?+=&%@~]*\")\n",
        "\n",
        "def preprocess(text):\n",
        "    p_text = hashtag_re.sub(\"[hashtag]\",text)\n",
        "    p_text = mention_re.sub(\"[mention]\",p_text)\n",
        "    p_text = url_re.sub(\"[url]\",p_text)\n",
        "    p_text = ftfy.fix_text(p_text)\n",
        "    return p_text.lower()\n",
        "\n",
        "tokenise_re = re.compile(r\"(\\[[^\\]]+\\]|[-'\\w]+|[^\\s\\w\\[']+)\") #([]|words|other non-space)\n",
        "def tokenise(text):\n",
        "    return tokenise_re.findall(text)\n",
        "\n",
        "class Document:\n",
        "    def __init__(self, meta={}):\n",
        "        self.meta = meta\n",
        "        self.tokens_fql = Counter() #empty Counter, ready to be added to with Counter.update.\n",
        "        self.pos_fql = Counter()\n",
        "        self.pos_list = [] #empty list for pos tags from running text.\n",
        "        self.num_tokens = 0\n",
        "        self.text = \"\"\n",
        "        \n",
        "    def extract_features_from_text(self, text):\n",
        "        self.text += text\n",
        "        p_text = preprocess(text)\n",
        "        tokens = tokenise(p_text)\n",
        "        lower_tokens = [t.lower() for t in tokens]\n",
        "        self.num_tokens += len(lower_tokens)\n",
        "        self.tokens_fql.update(lower_tokens) #updating Counter counts items in list, adding to existing Counter items.\n",
        "        pos_tagged = nltk.pos_tag(tokens)\n",
        "        pos = [tag[1] for tag in pos_tagged]\n",
        "        self.pos_fql.update(pos)\n",
        "        self.pos_list.extend(pos)\n",
        "        \n",
        "    def extract_features_from_texts(self, texts): #texts should be iterable text lines, e.g. read in from file.\n",
        "        for text in texts:\n",
        "            extract_features_from_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPOg0RSFnAL9"
      },
      "outputs": [],
      "source": [
        "class DocumentProcessor(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, process_method):\n",
        "        self.process_method = process_method\n",
        "    \n",
        "    def fit(self, X, y=None): #no fitting necessary, although could use this to build a vocabulary for all documents, and then limit to set (e.g. top 1000).\n",
        "        return self\n",
        "\n",
        "    def transform(self, documents):\n",
        "        for document in documents:\n",
        "            yield self.process_method(document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiMXqAJOnAL-"
      },
      "outputs": [],
      "source": [
        "def get_tokens_fql(document):\n",
        "    return document.tokens_fql\n",
        "\n",
        "def get_pos_fql(document):\n",
        "    return document.pos_fql\n",
        "\n",
        "def read_list(file):\n",
        "    with open(file) as f:\n",
        "        items = []\n",
        "        lines = f.readlines()\n",
        "        for line in lines:\n",
        "            items.append(line.strip())\n",
        "    return items\n",
        "\n",
        "fws = read_list(working_folder + \"functionwords.txt\")\n",
        "\n",
        "def get_fws_fql(document):\n",
        "    fws_fql = Counter({t: document.tokens_fql[t] for t in fws}) #dict comprehension, t: fql[t] is token: freq.\n",
        "    return +fws_fql"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJnUVTo1nAL_"
      },
      "source": [
        "Here the Tweets are imported and put into a `Document` instance for each Tweet. This could be edited easily to use in CountVectorizer, just return a list containing the tweet text, and a list containing the labels. All Tweets available from SemEval data are combined here, allowing for our own train/test split or cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8DA8kNHnAMA"
      },
      "outputs": [],
      "source": [
        "def import_tweets_docs(file, label):\n",
        "    metadata = {'label': label}\n",
        "    with open(file) as f:\n",
        "        tweets = f.readlines()\n",
        "        for tweet in tweets:\n",
        "            doc = Document(meta=metadata)\n",
        "            doc.extract_features_from_text(tweet)\n",
        "            yield doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQPeiAq3nAMB"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "corpus.extend(import_tweets_docs(working_folder + \"sentiment/all/negative.txt\", \"negative\"))\n",
        "corpus.extend(import_tweets_docs(working_folder + \"sentiment/all/positive.txt\", \"positive\"))\n",
        "corpus.extend(import_tweets_docs(working_folder + \"sentiment/all/neutral.txt\", \"neutral\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pii0Ekq0nAMB"
      },
      "outputs": [],
      "source": [
        "y = [d.meta['label'] for d in corpus]\n",
        "X = corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyHAxNe8nAMC"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 0, stratify=y)\n",
        "print(len(X_train), len(X_test))\n",
        "print(len(y_train), len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHhclRvOnAME"
      },
      "outputs": [],
      "source": [
        "negative_words = []\n",
        "    \n",
        "with open(working_folder + \"sentiment/opinion-lexicon-English/negative-words-utf8.txt\", \"w\") as f:\n",
        "    for word in negative_words:\n",
        "        f.write(f\"{word}\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmKUPYPjnAME"
      },
      "outputs": [],
      "source": [
        "positive_words = []\n",
        "    \n",
        "with open(working_folder + \"sentiment/opinion-lexicon-English/positive-words-utf8.txt\", \"w\") as f:\n",
        "    for word in positive_words:\n",
        "        f.write(f\"{word}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sQwLtjsnAMF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "413-wk19-sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}