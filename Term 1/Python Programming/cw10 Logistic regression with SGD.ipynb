{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM6WkeDwx0mGCbddjjnEM8p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cXAiNs69-NB4"},"outputs":[],"source":["import random\n","#import math\n","import numpy as np\n","random.seed(0)\n","class LogisticRegression:\n","    \n","    def __init__(self,alpha = 0.15):\n","        self.alpha = alpha\n","        self.weights = None\n","        self.bias = None\n","        \n","    def sigmoid(self,z):\n","        return 1/(1+ np.exp(-z))\n","    \n","    def loss (self,y,y_hat):\n","        loss = np.mean((y-y_hat)**2)\n","        return loss\n","        \n","    def train(self,dataset,label,n = 200):\n","        #loss = []\n","        mse = []\n","        dataset = np.array(dataset)\n","        \n","        self.weights = [0.1 for i in range((dataset.shape[1]))]\n","        self.bias = 0.1\n","        \n","        for epoch in range(n):\n","            c = list(zip(dataset,label))\n","            random.shuffle(c)\n","            shuf_data,shuf_label = zip(*c)\n","            shuf_data = np.array(shuf_data)\n","            shuf_label = np.array(shuf_label)\n","            sum_error = 0\n","            for index,row in enumerate(shuf_data):\n","                print (f\"index{index} - {self.bias}, {self.weights}, {row}\") \n","                linear_equation = np.dot(self.weights, row) + self.bias\n","                y_predicted = self.sigmoid( linear_equation)\n","                print(y_predicted)\n","                #print(y_predicted)\n","                sum_error += self.loss(y_predicted,shuf_label[index])\n","                error = y_predicted - shuf_label[index]\n","                #sum_error += (error**2)\n","                #print(self.bias)\n","                self.bias = self.bias - self.alpha * error * y_predicted* (1-y_predicted)\n","                for j in range(len(row)):\n","                    self.weights[j] = self.weights[j] - self.alpha * error * y_predicted * (1-y_predicted) * row[j]\n","                #print(self.weights)\n","                #print(self.bias, self.weights)\n","                    \n","            mse.append(sum_error/len(shuf_data))\n","        \n","        return mse\n","    \n","    def classify(self,dataset,threshold):\n","        predicton = self.sigmoid(np.dot(dataset,self.weights)+ self.bias)\n","        #final_pred = []\n","        final_pred = [1 if i > threshold else 0 for i in predicton]\n","        return final_pred\n","\n","def printRounded(myList):\n","    print(\"[\",end=\"\")\n","    for i in range(len(myList)-1):\n","        print(str(round(myList[i],7)),end=\", \")\n","    print(str(round(myList[-1],7)),end=\"]\\n\")"]},{"cell_type":"code","source":["dataset = [[0, 0], [1, 0], [2, 1], [1, 2], [3, 1], [4, 1], [5, 2], [3, 3], [2, 5]]\n","labels = [0, 0, 0, 0, 0, 1, 1, 1, 1]\n","\n","\n","lr = LogisticRegression()\n","\n","MSEList = lr.train(dataset, labels, 20)\n","\n","predictedLabels = lr.classify(dataset, 0.5)\n","print(predictedLabels)\n","printRounded(MSEList)"],"metadata":{"id":"PNKquVMd-PuC"},"execution_count":null,"outputs":[]}]}