{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pesmi0kmgR_C"
      },
      "source": [
        "# SCC.413 Applied Data Mining\n",
        "# NLP: Week 16\n",
        "# Twitter Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju0S_WtigR_F"
      },
      "source": [
        "## Contents\n",
        "- [Introduction](#intro)\n",
        "- [Packages & imports](#packages)\n",
        "- [Authentication](#authentication)\n",
        "- [User timelines](#user)\n",
        "- [Searching for tweets](#searching)\n",
        "    - [Search operators](#search_ops)\n",
        "- [Outputting tweets](#outputting)\n",
        "- [Exercise](#exercise)\n",
        "- [Further tasks](#tasks)\n",
        "- [Advanced tasks](#advanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma3EIY-lgR_H"
      },
      "source": [
        "<a name=\"intro\"></a>\n",
        "## Introduction\n",
        "\n",
        "In this lab exercise you will interact with the [Twitter REST API](https://developer.twitter.com/en/docs) using Python code to download tweets for future analysis. Data collected via APIs are generally much cleaner than web scraped data, and also structured nicely (here, via JSON) for easy querying.\n",
        "\n",
        "To collect data from Twitter you need to have a Twitter account, and also create an authorised application. If you do not want to do this, you could skip most of this lab and just use pre-collected data, although it is useful to see how to collect your own data. One option would be to partner with a neighbour and use a single Twitter account. As a minimum, you should observe how you can read in previously collected Twitter data, and output this in a different format (see [Outputting tweets](#outputting), and [Exercise](#exercise)).\n",
        "\n",
        "Ensure you have downloaded the code from the git repository (as described on Moodle), and place it in a folder for this lab. Your h-drive is probably the best place, although keep an eye on the space available with the various data files you will be creating in the lab.\n",
        "\n",
        "The code provides a functions collecting Twitter data via the [Twitter REST API](https://developer.twitter.com/en/docs). We use the [Twython](https://github.com/ryanmcgrath/twython) Python package to assist us, although others are available, most notably [Tweepy](https://github.com/tweepy/tweepy).\n",
        "\n",
        "Ensure you have completed the separate instructions for creating a developer account and Twitter app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y48b3PsPgR_I"
      },
      "source": [
        "<a name=\"packages\"></a>\n",
        "## Packages & Imports\n",
        "\n",
        "The Twython package will need installing on Google Colab, as below. Non-standard packages are also included in `requirements.txt`, if you need to install them on your own machine."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install twython"
      ],
      "metadata": {
        "id": "2IWANgaXgbD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should upload all of the provided files to a Google Drive folder, you can then access these files from your Python code. See also the files tab."
      ],
      "metadata": {
        "id": "tS7ckSyCBCoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "id": "ydCluoej2UY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code adds a folder from Google Drive. You may need to edit the path to match your own."
      ],
      "metadata": {
        "id": "ktoDdLMkBVMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/413/wk16')"
      ],
      "metadata": {
        "id": "Cq_7TvOW34v5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbsOxqH_gR_J"
      },
      "source": [
        "This particular lab uses the Twython package. Other imports are included in one cell here for convenience.\n",
        "\n",
        "To interact with the Twitter API, you need developer credentials, with a the *Consumer Key (API Key)*, *Consumer Secret (API Secret)*, *Access Token*, and *Access Token Secret*. These should be copied and saved into the relevant variables in `twitter_auth.py` before running the cells below. The authorisation variables are read in with the import below. You can replace the import and add the variables directly here (though this is not good practice, as it reveals your credentials)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6vMwytGhgR_K"
      },
      "outputs": [],
      "source": [
        "from twython import Twython, TwythonError, TwythonRateLimitError #https://github.com/ryanmcgrath/twython\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "\n",
        "from twitter_auth import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtxTHcrfgR_M"
      },
      "source": [
        "<a name=\"authentication\"></a>\n",
        "## Authentication\n",
        "\n",
        "Our hook into the Twitter API is via [Twython](https://github.com/ryanmcgrath/twython), and we make API calls via functions on a Twitter authenticated Twython object. We create and authorise this below, with supplied credentials (from `twitter_auth.py`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QfIkBQEgR_N"
      },
      "outputs": [],
      "source": [
        "twitter = Twython(consumer_key, consumer_secret, access_token, access_secret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV3IcmN6gR_O"
      },
      "source": [
        "<a name=\"user\"></a>\n",
        "## User timelines\n",
        "\n",
        "The Twitter API allows for the downloading of any (unprotected) user's tweets, limited to their last 3,200. Collecting a user's tweets can be useful for various research questions, such as comparing language usage across individuals/organisations, and for performing various authorship analysis tasks (as we'll see later in the module).\n",
        "\n",
        "A function is provided below for collecting a given user's Tweets. Review the code and check your understanding of how it is collecting tweets. The function is also available from `user_tweets.py`.\n",
        "\n",
        "The Twitter API throttles the downloading of data, here allowing for 200 tweets per request, and 1,500 requests per 15-minute window (and 100,000 requests per day). Therefore we need to collect 200 tweets at a time, with an older starting point each time, until there are no more tweets available. If we hit the [rate limit](https://developer.twitter.com/en/docs/basics/rate-limiting), we pause the collection until the rate-limit window resets. Other options are available for the collecting the user tweets: [user timeline](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline.html). How would you discard tweets which are replies to other users?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "2hydfcArgR_P"
      },
      "outputs": [],
      "source": [
        "def get_user_tweets(twitter, screen_name, **kwargs):\n",
        "    \"\"\"uses twitter (Twython object) to collect tweets from user with screen_name (no @), can include extra search parameters for get_user_timeline, returns list of tweets\"\"\"\n",
        "    \n",
        "    #initialize a list to hold all the tweets\n",
        "    user_tweets = []\n",
        "    try:\n",
        "        #make initial request for most recent tweets (200 is the maximum allowed count).\n",
        "        #We normally don't want retweets, so we set include_rts to false.\n",
        "        #tweet_mode=\"extended\" allows for full text tweets, rather than truncated (i.e. over 140 chars)\n",
        "        #https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline.html\n",
        "        new_tweets = twitter.get_user_timeline(screen_name=screen_name,count=200,include_rts=False,tweet_mode=\"extended\", **kwargs)\n",
        "\n",
        "        #add to list\n",
        "        user_tweets.extend(new_tweets)\n",
        "\n",
        "        #save the id of the oldest tweet less one, this is the starting point for collecting further tweets.\n",
        "        oldest = user_tweets[-1]['id'] - 1\n",
        "        #keep grabbing tweets until there are no tweets left to grab. Twitter limits us to 3,200 (including retweets)\n",
        "        while len(new_tweets) > 0:\n",
        "            try:\n",
        "                #all subsequent requests use the max_id param to prevent duplicates\n",
        "                new_tweets = twitter.get_user_timeline(screen_name=screen_name,count=200,include_rts=False,tweet_mode=\"extended\",max_id=oldest, **kwargs)\n",
        "                user_tweets.extend(new_tweets)\n",
        "                oldest = user_tweets[-1]['id'] - 1\n",
        "                print(\"...%s tweets downloaded so far\" % (len(user_tweets)))\n",
        "            except TwythonRateLimitError as e:\n",
        "                #We have hit the rate limit, so we need to take a break.\n",
        "                #find how much time need to sleep for.\n",
        "                remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "                print(\"sleeping for %d seconds\" % remainder)\n",
        "                #Pause until we can go again.\n",
        "                time.sleep(remainder)\n",
        "                continue\n",
        "                \n",
        "    except TwythonRateLimitError as e:\n",
        "        #We have hit the rate limit on first call, so we need to take a break, and start again.\n",
        "        #find how much time need to sleep for.\n",
        "        remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "        print(\"sleeping for %d seconds\" % remainder)\n",
        "        #Pause until we can go again.\n",
        "        time.sleep(remainder)\n",
        "        #start again\n",
        "        return get_user_tweets(twitter, screen_name, **kwargs)\n",
        "\n",
        "    except TwythonError as e:\n",
        "        print(e)\n",
        "\n",
        "    return user_tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAxSM06XgR_S"
      },
      "source": [
        "To collect tweets for a user, we simply call the method, providing our authenticated Twython object (twitter), and a twitter user screen name (without the @). Below we collect [Lancaster University's twitter timeline](https://twitter.com/LancasterUni)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWxJ4d1vgR_U"
      },
      "outputs": [],
      "source": [
        "tweets = get_user_tweets(twitter, \"LancasterUni\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noJHk1pygR_W"
      },
      "source": [
        "This returns a list of tweet dictionary objects. A lot of information is provided per Tweet. The attributes are detailed for [Tweet objects in the API](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object). Review the information that is available.\n",
        "\n",
        "The first tweet will be the latest tweet. You can see the list of keys, and a full tweet below. We can also view individual attributes, such as the tweet text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkSZG8QWgR_X"
      },
      "outputs": [],
      "source": [
        "print(tweets[0].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT07-Fr4gR_Z"
      },
      "outputs": [],
      "source": [
        "print(tweets[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBkOvjEmgR_a"
      },
      "outputs": [],
      "source": [
        "tweets = get_user_tweets(twitter, \"UCREL_NLP\")\n",
        "print(tweets[0]['full_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DjlN0G-gR_c"
      },
      "source": [
        "<a name=\"searching\"></a>\n",
        "## Searching for tweets\n",
        "\n",
        "The Twitter API also allows for the searching for Tweets, albeit only over a sample from the last 7 days (unless you pay). This could be useful for collecting a selection of tweets on specific topic, or mentioning people.\n",
        "\n",
        "A function is provided below for performing searches, in a similar manner to extracting a user’s tweets. Review and check your understanding of the code. The function is also available from `search_tweets.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RP092XAagR_d"
      },
      "outputs": [],
      "source": [
        "def search_twitter(twitter, search_term, limit, **kwargs):\n",
        "    \"\"\"uses twitter (Twython object) to collect tweets returned from given search_term, up to limit, , can include extra search parameters, returns list of tweets\"\"\"\n",
        "    \n",
        "    #initialise list of tweets\n",
        "    tweets = []\n",
        "\n",
        "    try:\n",
        "        #count=100 is the maximum allowed\n",
        "        #tweet_mode=\"extended\" allows for full text tweets, rather than truncated (i.e. over 140 chars)\n",
        "        #https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html\n",
        "        search_results = twitter.search(q=search_term,tweet_mode=\"extended\",count=100, **kwargs)\n",
        "        tweets.extend(search_results['statuses'])\n",
        "\n",
        "        if len(tweets) == 0:\n",
        "            print(\"No results found\")\n",
        "            return tweets\n",
        "        \n",
        "        #save the id of the oldest tweet less one, this is the starting point for collecting further tweets.\n",
        "        oldest = tweets[-1]['id'] - 1\n",
        "        #keep grabbing tweets until there are no tweets left to grab.\n",
        "        while len(search_results['statuses']) > 0 and len(tweets) < limit:\n",
        "            try:\n",
        "                #all subsequent requests use the max_id param to prevent duplicates\n",
        "                search_results = twitter.search(q=search_term,tweet_mode=\"extended\",count=100,max_id=oldest, **kwargs)\n",
        "                tweets.extend(search_results['statuses'])\n",
        "                oldest = tweets[-1]['id'] - 1\n",
        "                print(\"...%s tweets downloaded so far\" % (len(tweets)))\n",
        "            except TwythonRateLimitError as e:\n",
        "                #We have hit the rate limit, so we need to take a break.\n",
        "                #find how much time need to sleep for.\n",
        "                remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "                print(\"sleeping for %d seconds\" % remainder)\n",
        "                #Pause until we can go again.\n",
        "                time.sleep(remainder)\n",
        "                continue\n",
        "\n",
        "    except TwythonRateLimitError as e:\n",
        "        #We have hit the rate limit on first call, so we need to take a break, and start again.\n",
        "        #find how much time need to sleep for.\n",
        "        remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "        print(\"sleeping for %d seconds\" % remainder)\n",
        "        #Pause until we can go again.\n",
        "        time.sleep(remainder)\n",
        "        #start again\n",
        "        return search_twitter(twitter, search_term, limit, **kwargs)\n",
        "                \n",
        "    except TwythonError as e:\n",
        "        print(e)\n",
        "\n",
        "    return tweets[:limit]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE0IIi9LgR_e"
      },
      "source": [
        "To search, simply provide a search string and a limit of the number of tweets to return, e.g. to get 500 tweets with the hashtag #NLProc (common hashtag for NLP related stuff):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx_KNfyugR_f"
      },
      "outputs": [],
      "source": [
        "tweets = search_twitter(twitter, \"#NLProc\", 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJoXeZmbgR_g"
      },
      "outputs": [],
      "source": [
        "print(tweets[0][\"full_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeZ3HAr_gR_g"
      },
      "source": [
        "<a name=\"search_ops\"></a>\n",
        "### Search operators\n",
        "\n",
        "The are a number of search operators available, allowing for quite complex searches: [search operators](https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators). Ignore the instructions on URL encoding the search string, *Twython* takes care of this for us.\n",
        "\n",
        "Search strings can be built up with multiple parameters. For example, to search for tweets from the *@LancasterUni* account mentioning *research*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE86yMV7gR_h"
      },
      "outputs": [],
      "source": [
        "tweets = search_twitter(twitter, \"from:LancasterUni research\", 10)\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOggLlZtgR_i"
      },
      "source": [
        "There are also different parameters available for the search request itself: [search parameters](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html).\n",
        "\n",
        "These can be passed through the search_twitter method (using [kwargs](https://book.pythontips.com/en/latest/args_and_kwargs.html)). For example, to restrict a search to only tweets in English:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSHtGJP2gR_j"
      },
      "outputs": [],
      "source": [
        "tweets = search_twitter(twitter, \"\\\"faux pas\\\"\", 10, lang='en')\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNXumE4cgR_j"
      },
      "source": [
        "Try this with \"fr\", and without specifying the language to see the difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAd2CEPpgR_k"
      },
      "source": [
        "<a name=\"outputting\"></a>\n",
        "## Outputting tweets\n",
        "\n",
        "To create a corpus for later use, you may want to save tweets to a file. A series of functions are provided below to output to JSON, plain text, and also to read in JSON saved tweets. Review and check your understanding of these functions. These are also provided in `tweets_json.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6hDRMVAYgR_k"
      },
      "outputs": [],
      "source": [
        "def to_full_json(tweets, filepath=\"tweets.json\"):\n",
        "    \"\"\"Saves to filepath with the provided tweets with all attributes, in JSON.\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        #Dump json file. indent=4 prints the output prettier, but will increase disk space.\n",
        "        json.dump(tweets, f, indent=4)\n",
        "\n",
        "def to_minimal_json(tweets, filepath=\"tweets.json\"):\n",
        "    #This reduces each tweet to the set of keys (attributes) listed.\n",
        "    #Other attributes can be used here, see https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object\n",
        "    atts=['id_str', 'full_text']\n",
        "    minimal_tweets = [{k:tweet[k] for k in atts} for tweet in tweets]\n",
        "    with open(filepath, 'w') as f:\n",
        "        #Dump json file. indent=4 prints the output prettier, but will increase disk space.\n",
        "        json.dump(minimal_tweets, f, indent=4)\n",
        "\n",
        "def to_just_text(tweets, filepath=\"tweets.txt\"):\n",
        "    \"\"\"Saves to filepath with the provided tweets in plaintext, one tweet per line\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        for tweet in tweets:\n",
        "            #Linebreaks are replaced so we have one tweet per line.\n",
        "            f.write(\"{}\\n\".format(tweet['full_text'].replace(\"\\n\", \"  \").replace(\"\\r\", \"  \")))\n",
        "            \n",
        "def load_json_tweets(filepath):\n",
        "    \"\"\"Loads a JSON file into a list of tweet dictionary objects\"\"\"\n",
        "    tweets = json.load(open(filepath))\n",
        "    return tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yjwml_2gR_l"
      },
      "source": [
        "The full JSON can be saved, although note that this will take up some space. You can save to minimal JSON, and plain text by using the different functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ALrjPPYcgR_l"
      },
      "outputs": [],
      "source": [
        "to_minimal_json(tweets, \"@LancasterUni-min.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2pLANPxgR_m"
      },
      "source": [
        "To load in previously saved tweets, just use load_json_tweets, as below, to load in the provided UCREL tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgYbgikEgR_m"
      },
      "outputs": [],
      "source": [
        "ucrel_tweets = load_json_tweets(\"@UCREL_NLP-full.json\")\n",
        "print(ucrel_tweets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QI2CaTVgR_n"
      },
      "source": [
        "<a name=\"exercise\"></a>\n",
        "## Exercise\n",
        "\n",
        "Using the [list of attributes available](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object), produce a list of tweets (in JSON format or plain text, e.g. separated by a tab (TSV)) containing the time the tweet was written and the text. Of course, there are numerous ways the tweets could be outputted, e.g. into a database or a CSV file. Feel free to experiment with different outputs that might be useful to you. You can use the provided UCREL_NLP tweets(`@UCREL_NLP-full.json`) for this, or any other collection of tweets you have made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "XRfLXx_bgR_n"
      },
      "outputs": [],
      "source": [
        "# Exercise 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyCLptlWgR_p"
      },
      "source": [
        "<a name=\"tasks\"></a>\n",
        "## Further Tasks\n",
        "\n",
        "Come up with your own searches, and discuss with your neighbors. A few you can try:\n",
        "\n",
        "1. Find tweets mentioning *paper* and the *#NLProc* hashtag, which are not retweets.\n",
        "2. Find 10 positive tweets about *rain*, and 10 negative tweets about *rain*.\n",
        "3. Find Tweets **to or from** *@LancasterUni* mentioning *storm*, *wet* or *rain*.\n",
        "4. Find recent tweets mentioning *snow*.\n",
        "5. Find tweets mentioning *rain* from the Lancaster area.\n",
        "\n",
        "Also, think about what useful tweet attributes are available to output for the above searches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ywsCH4xgR_p"
      },
      "outputs": [],
      "source": [
        "# optional 1. Find tweets mentioning paper and the #NLProc hashtag, which are not retweets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJz7eag0gR_q"
      },
      "outputs": [],
      "source": [
        "# optional 2. Find 10 positive tweets about rain, and 10 negative tweets about rain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGw7YM09gR_r"
      },
      "outputs": [],
      "source": [
        "# optional 3. Find Tweets to or from @LancasterUni mentioning *storm, *wet* or *rain*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMzjzfl-gR_r"
      },
      "outputs": [],
      "source": [
        "# optional 4. Find recent tweets mentioning snow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDmNs5L3gR_s"
      },
      "outputs": [],
      "source": [
        "# optional 5. Find tweets mentioning rain from the Lancaster area.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEb8Ji6qgR_t"
      },
      "outputs": [],
      "source": [
        "# optional -- additional searches\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdrVdWHagR_t"
      },
      "source": [
        "<a name=\"advanced\"></a>\n",
        "## Optional advanced tasks\n",
        "\n",
        "\n",
        "The Twitter API provides access to further information about tweets, users, and plenty more. Here’s a list of things you can try if you have time. Please feel free to make other suggestions.\n",
        "\n",
        "1. Many other methods are available from Twython linked to Twitter API requests: https://twython.readthedocs.io/en/latest/api.html. One potentially useful task you should be able perform by adapting the available code is to collect the user details of a given account (see *show_user*).\n",
        "2. Expanding on 1., you could collect a list of users (e.g. a user's followers) and then collect all of their user information and tweets.\n",
        "3. You can use the Twitter Streaming API to collect tweets in real-time as they are posted. See the instructions for implementing this with Twython: https://twython.readthedocs.io/en/latest/usage/streaming_api.html, and attempt to collect all tweets mentioning a word of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVXUaBK7gR_u"
      },
      "outputs": [],
      "source": [
        "# Advanced 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4YFgdBJgR_v"
      },
      "outputs": [],
      "source": [
        "# Advanced 2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aF8f4ZnhgR_w"
      },
      "outputs": [],
      "source": [
        "# Advanced 3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m76o2qLDgR_w"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "413-wk16-Twitter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}