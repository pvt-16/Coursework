{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pesmi0kmgR_C"
      },
      "source": [
        "# SCC.413 Applied Data Mining\n",
        "# NLP: Week 16\n",
        "# Twitter Data Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju0S_WtigR_F"
      },
      "source": [
        "## Contents\n",
        "- [Introduction](#intro)\n",
        "- [Packages & imports](#packages)\n",
        "- [Authentication](#authentication)\n",
        "- [User timelines](#user)\n",
        "- [Searching for tweets](#searching)\n",
        "    - [Search operators](#search_ops)\n",
        "- [Outputting tweets](#outputting)\n",
        "- [Exercise](#exercise)\n",
        "- [Further tasks](#tasks)\n",
        "- [Advanced tasks](#advanced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma3EIY-lgR_H"
      },
      "source": [
        "<a name=\"intro\"></a>\n",
        "## Introduction\n",
        "\n",
        "In this lab exercise you will interact with the [Twitter REST API](https://developer.twitter.com/en/docs) using Python code to download tweets for future analysis. Data collected via APIs are generally much cleaner than web scraped data, and also structured nicely (here, via JSON) for easy querying.\n",
        "\n",
        "To collect data from Twitter you need to have a Twitter account, and also create an authorised application. If you do not want to do this, you could skip most of this lab and just use pre-collected data, although it is useful to see how to collect your own data. One option would be to partner with a neighbour and use a single Twitter account. As a minimum, you should observe how you can read in previously collected Twitter data, and output this in a different format (see [Outputting tweets](#outputting), and [Exercise](#exercise)).\n",
        "\n",
        "Ensure you have downloaded the code from the git repository (as described on Moodle), and place it in a folder for this lab. Your h-drive is probably the best place, although keep an eye on the space available with the various data files you will be creating in the lab.\n",
        "\n",
        "The code provides a functions collecting Twitter data via the [Twitter REST API](https://developer.twitter.com/en/docs). We use the [Twython](https://github.com/ryanmcgrath/twython) Python package to assist us, although others are available, most notably [Tweepy](https://github.com/tweepy/tweepy).\n",
        "\n",
        "Ensure you have completed the separate instructions for creating a developer account and Twitter app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y48b3PsPgR_I"
      },
      "source": [
        "<a name=\"packages\"></a>\n",
        "## Packages & Imports\n",
        "\n",
        "The Twython package will need installing on Google Colab, as below. Non-standard packages are also included in `requirements.txt`, if you need to install them on your own machine."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install twython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IWANgaXgbD5",
        "outputId": "6f6c0662-788c-429f-adcd-e36d744c3174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting twython\n",
            "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from twython) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.2.0)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should upload all of the provided files to a Google Drive folder, you can then access these files from your Python code. See also the files tab."
      ],
      "metadata": {
        "id": "tS7ckSyCBCoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydCluoej2UY8",
        "outputId": "a122f930-6e8d-413f-abb3-7131bf53d6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code adds a folder from Google Drive. You may need to edit the path to match your own."
      ],
      "metadata": {
        "id": "ktoDdLMkBVMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/413/wk16')"
      ],
      "metadata": {
        "id": "Cq_7TvOW34v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbsOxqH_gR_J"
      },
      "source": [
        "This particular lab uses the Twython package. Other imports are included in one cell here for convenience.\n",
        "\n",
        "To interact with the Twitter API, you need developer credentials, with a the *Consumer Key (API Key)*, *Consumer Secret (API Secret)*, *Access Token*, and *Access Token Secret*. These should be copied and saved into the relevant variables in `twitter_auth.py` before running the cells below. The authorisation variables are read in with the import below. You can replace the import and add the variables directly here (though this is not good practice, as it reveals your credentials)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vMwytGhgR_K"
      },
      "outputs": [],
      "source": [
        "from twython import Twython, TwythonError, TwythonRateLimitError #https://github.com/ryanmcgrath/twython\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "\n",
        "from twitter_auth import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtxTHcrfgR_M"
      },
      "source": [
        "<a name=\"authentication\"></a>\n",
        "## Authentication\n",
        "\n",
        "Our hook into the Twitter API is via [Twython](https://github.com/ryanmcgrath/twython), and we make API calls via functions on a Twitter authenticated Twython object. We create and authorise this below, with supplied credentials (from `twitter_auth.py`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QfIkBQEgR_N"
      },
      "outputs": [],
      "source": [
        "twitter = Twython(consumer_key, consumer_secret, access_token, access_secret)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV3IcmN6gR_O"
      },
      "source": [
        "<a name=\"user\"></a>\n",
        "## User timelines\n",
        "\n",
        "The Twitter API allows for the downloading of any (unprotected) user's tweets, limited to their last 3,200. Collecting a user's tweets can be useful for various research questions, such as comparing language usage across individuals/organisations, and for performing various authorship analysis tasks (as we'll see later in the module).\n",
        "\n",
        "A function is provided below for collecting a given user's Tweets. Review the code and check your understanding of how it is collecting tweets. The function is also available from `user_tweets.py`.\n",
        "\n",
        "The Twitter API throttles the downloading of data, here allowing for 200 tweets per request, and 1,500 requests per 15-minute window (and 100,000 requests per day). Therefore we need to collect 200 tweets at a time, with an older starting point each time, until there are no more tweets available. If we hit the [rate limit](https://developer.twitter.com/en/docs/basics/rate-limiting), we pause the collection until the rate-limit window resets. Other options are available for the collecting the user tweets: [user timeline](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline.html). How would you discard tweets which are replies to other users?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hydfcArgR_P"
      },
      "outputs": [],
      "source": [
        "def get_user_tweets(twitter, screen_name, **kwargs):\n",
        "    \"\"\"uses twitter (Twython object) to collect tweets from user with screen_name (no @), can include extra search parameters for get_user_timeline, returns list of tweets\"\"\"\n",
        "    \n",
        "    #initialize a list to hold all the tweets\n",
        "    user_tweets = []\n",
        "    try:\n",
        "        #make initial request for most recent tweets (200 is the maximum allowed count).\n",
        "        #We normally don't want retweets, so we set include_rts to false.\n",
        "        #tweet_mode=\"extended\" allows for full text tweets, rather than truncated (i.e. over 140 chars)\n",
        "        #https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline.html\n",
        "        new_tweets = twitter.get_user_timeline(screen_name=screen_name,count=200,include_rts=False,tweet_mode=\"extended\", **kwargs)\n",
        "\n",
        "        #add to list\n",
        "        user_tweets.extend(new_tweets)\n",
        "\n",
        "        #save the id of the oldest tweet less one, this is the starting point for collecting further tweets.\n",
        "        oldest = user_tweets[-1]['id'] - 1\n",
        "        #keep grabbing tweets until there are no tweets left to grab. Twitter limits us to 3,200 (including retweets)\n",
        "        while len(new_tweets) > 0:\n",
        "            try:\n",
        "                #all subsequent requests use the max_id param to prevent duplicates\n",
        "                new_tweets = twitter.get_user_timeline(screen_name=screen_name,count=200,include_rts=False,tweet_mode=\"extended\",max_id=oldest, **kwargs)\n",
        "                user_tweets.extend(new_tweets)\n",
        "                oldest = user_tweets[-1]['id'] - 1\n",
        "                print(\"...%s tweets downloaded so far\" % (len(user_tweets)))\n",
        "            except TwythonRateLimitError as e:\n",
        "                #We have hit the rate limit, so we need to take a break.\n",
        "                #find how much time need to sleep for.\n",
        "                remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "                print(\"sleeping for %d seconds\" % remainder)\n",
        "                #Pause until we can go again.\n",
        "                time.sleep(remainder)\n",
        "                continue\n",
        "                \n",
        "    except TwythonRateLimitError as e:\n",
        "        #We have hit the rate limit on first call, so we need to take a break, and start again.\n",
        "        #find how much time need to sleep for.\n",
        "        remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "        print(\"sleeping for %d seconds\" % remainder)\n",
        "        #Pause until we can go again.\n",
        "        time.sleep(remainder)\n",
        "        #start again\n",
        "        return get_user_tweets(twitter, screen_name, **kwargs)\n",
        "\n",
        "    except TwythonError as e:\n",
        "        print(e)\n",
        "\n",
        "    return user_tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAxSM06XgR_S"
      },
      "source": [
        "To collect tweets for a user, we simply call the method, providing our authenticated Twython object (twitter), and a twitter user screen name (without the @). Below we collect [Lancaster University's twitter timeline](https://twitter.com/LancasterUni)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWxJ4d1vgR_U",
        "outputId": "43af9079-3fd7-4582-d9e0-2d3fc80d3577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...376 tweets downloaded so far\n",
            "...566 tweets downloaded so far\n",
            "...761 tweets downloaded so far\n",
            "...946 tweets downloaded so far\n",
            "...1125 tweets downloaded so far\n",
            "...1312 tweets downloaded so far\n",
            "...1483 tweets downloaded so far\n",
            "...1670 tweets downloaded so far\n",
            "...1858 tweets downloaded so far\n",
            "...2055 tweets downloaded so far\n",
            "...2255 tweets downloaded so far\n",
            "...2448 tweets downloaded so far\n",
            "...2628 tweets downloaded so far\n",
            "...2819 tweets downloaded so far\n",
            "...2996 tweets downloaded so far\n",
            "...3047 tweets downloaded so far\n",
            "...3047 tweets downloaded so far\n"
          ]
        }
      ],
      "source": [
        "tweets = get_user_tweets(twitter, \"LancasterUni\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noJHk1pygR_W"
      },
      "source": [
        "This returns a list of tweet dictionary objects. A lot of information is provided per Tweet. The attributes are detailed for [Tweet objects in the API](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object). Review the information that is available.\n",
        "\n",
        "The first tweet will be the latest tweet. You can see the list of keys, and a full tweet below. We can also view individual attributes, such as the tweet text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkSZG8QWgR_X",
        "outputId": "3ef38058-eb62-47c4-d9e9-d50d570187fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['created_at', 'id', 'id_str', 'full_text', 'truncated', 'display_text_range', 'entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])\n"
          ]
        }
      ],
      "source": [
        "print(tweets[0].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT07-Fr4gR_Z",
        "outputId": "c4dd3971-4dd2-4f18-b8e5-085104937d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'created_at': 'Tue Feb 22 13:44:01 +0000 2022', 'id': 1496118581712637961, 'id_str': '1496118581712637961', 'full_text': 'Using smartphone apps could reveal your identity, according to research by our Dr Heather Shaw (@H_Shawberry)üì±üîç\\n\\n@PsychScience @lancspsychres @LancsUniSciTech\\n\\nhttps://t.co/KTq6c5EwsJ', 'truncated': False, 'display_text_range': [0, 183], 'entities': {'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'H_Shawberry', 'name': 'Dr Heather Shaw', 'id': 87503878, 'id_str': '87503878', 'indices': [96, 108]}, {'screen_name': 'PsychScience', 'name': 'Association for Psychological Science', 'id': 19078387, 'id_str': '19078387', 'indices': [113, 126]}, {'screen_name': 'lancspsychres', 'name': 'Lancaster Psychology', 'id': 195781766, 'id_str': '195781766', 'indices': [127, 141]}, {'screen_name': 'LancsUniSciTech', 'name': 'Science & Technology at Lancaster', 'id': 25527873, 'id_str': '25527873', 'indices': [142, 158]}], 'urls': [{'url': 'https://t.co/KTq6c5EwsJ', 'expanded_url': 'https://www.lancaster.ac.uk/news/how-picking-up-your-smartphone-could-reveal-your-identity', 'display_url': 'lancaster.ac.uk/news/how-picki‚Ä¶', 'indices': [160, 183]}]}, 'source': '<a href=\"http://www.falcon.io\" rel=\"nofollow\">Falcon Social Media Management </a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 25521930, 'id_str': '25521930', 'name': 'Lancaster University', 'screen_name': 'LancasterUni', 'location': 'Lancaster, England', 'description': 'We‚Äôre a highly ranked collegiate university with a global reputation for teaching and research.', 'url': 'https://t.co/tiy4EYH1rT', 'entities': {'url': {'urls': [{'url': 'https://t.co/tiy4EYH1rT', 'expanded_url': 'http://www.lancaster.ac.uk', 'display_url': 'lancaster.ac.uk', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 65056, 'friends_count': 1182, 'listed_count': 778, 'created_at': 'Fri Mar 20 15:35:26 +0000 2009', 'favourites_count': 15931, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': True, 'statuses_count': 27234, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'FFFFFF', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/878207781827903488/RLv3roLp_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/878207781827903488/RLv3roLp_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/25521930/1628856423', 'profile_link_color': 'B6121B', 'profile_sidebar_border_color': 'FFFFFF', 'profile_sidebar_fill_color': 'FFFFFF', 'profile_text_color': '0A0101', 'profile_use_background_image': False, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none', 'withheld_in_countries': []}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 4, 'favorite_count': 7, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}\n"
          ]
        }
      ],
      "source": [
        "print(tweets[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBkOvjEmgR_a",
        "outputId": "40e85acc-d0fb-4038-8a1c-e8d533af389f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...108 tweets downloaded so far\n",
            "...139 tweets downloaded so far\n",
            "...168 tweets downloaded so far\n",
            "...240 tweets downloaded so far\n",
            "...240 tweets downloaded so far\n",
            "9/9 And we have more papers coming up next week @CL2021IE #CL2021 along with our colleagues in @CorpusSocialSci See you there! #NLProc #corpuslinguistics  https://t.co/iicYfmE1YB\n"
          ]
        }
      ],
      "source": [
        "tweets = get_user_tweets(twitter, \"UCREL_NLP\")\n",
        "print(tweets[0]['full_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DjlN0G-gR_c"
      },
      "source": [
        "<a name=\"searching\"></a>\n",
        "## Searching for tweets\n",
        "\n",
        "The Twitter API also allows for the searching for Tweets, albeit only over a sample from the last 7 days (unless you pay). This could be useful for collecting a selection of tweets on specific topic, or mentioning people.\n",
        "\n",
        "A function is provided below for performing searches, in a similar manner to extracting a user‚Äôs tweets. Review and check your understanding of the code. The function is also available from `search_tweets.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP092XAagR_d"
      },
      "outputs": [],
      "source": [
        "def search_twitter(twitter, search_term, limit, **kwargs):\n",
        "    \"\"\"uses twitter (Twython object) to collect tweets returned from given search_term, up to limit, , can include extra search parameters, returns list of tweets\"\"\"\n",
        "    \n",
        "    #initialise list of tweets\n",
        "    tweets = []\n",
        "\n",
        "    try:\n",
        "        #count=100 is the maximum allowed\n",
        "        #tweet_mode=\"extended\" allows for full text tweets, rather than truncated (i.e. over 140 chars)\n",
        "        #https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html\n",
        "        search_results = twitter.search(q=search_term,tweet_mode=\"extended\",count=100, **kwargs)\n",
        "        tweets.extend(search_results['statuses'])\n",
        "\n",
        "        if len(tweets) == 0:\n",
        "            print(\"No results found\")\n",
        "            return tweets\n",
        "        \n",
        "        #save the id of the oldest tweet less one, this is the starting point for collecting further tweets.\n",
        "        oldest = tweets[-1]['id'] - 1\n",
        "        #keep grabbing tweets until there are no tweets left to grab.\n",
        "        while len(search_results['statuses']) > 0 and len(tweets) < limit:\n",
        "            try:\n",
        "                #all subsequent requests use the max_id param to prevent duplicates\n",
        "                search_results = twitter.search(q=search_term,tweet_mode=\"extended\",count=100,max_id=oldest, **kwargs)\n",
        "                tweets.extend(search_results['statuses'])\n",
        "                oldest = tweets[-1]['id'] - 1\n",
        "                print(\"...%s tweets downloaded so far\" % (len(tweets)))\n",
        "            except TwythonRateLimitError as e:\n",
        "                #We have hit the rate limit, so we need to take a break.\n",
        "                #find how much time need to sleep for.\n",
        "                remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "                print(\"sleeping for %d seconds\" % remainder)\n",
        "                #Pause until we can go again.\n",
        "                time.sleep(remainder)\n",
        "                continue\n",
        "\n",
        "    except TwythonRateLimitError as e:\n",
        "        #We have hit the rate limit on first call, so we need to take a break, and start again.\n",
        "        #find how much time need to sleep for.\n",
        "        remainder = float(twitter.get_lastfunction_header(header='x-rate-limit-reset')) - time.time()\n",
        "        print(\"sleeping for %d seconds\" % remainder)\n",
        "        #Pause until we can go again.\n",
        "        time.sleep(remainder)\n",
        "        #start again\n",
        "        return search_twitter(twitter, search_term, limit, **kwargs)\n",
        "                \n",
        "    except TwythonError as e:\n",
        "        print(e)\n",
        "\n",
        "    return tweets[:limit]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE0IIi9LgR_e"
      },
      "source": [
        "To search, simply provide a search string and a limit of the number of tweets to return, e.g. to get 500 tweets with the hashtag #NLProc (common hashtag for NLP related stuff):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx_KNfyugR_f",
        "outputId": "c52fb1b3-a3cc-44a6-c7c2-0600ddb6610d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...175 tweets downloaded so far\n",
            "...267 tweets downloaded so far\n",
            "...367 tweets downloaded so far\n",
            "...467 tweets downloaded so far\n",
            "...557 tweets downloaded so far\n"
          ]
        }
      ],
      "source": [
        "tweets = search_twitter(twitter, \"#NLProc\", 500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJoXeZmbgR_g",
        "outputId": "c1b0dcab-7635-4acc-e508-b168adf4e5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The three PhD positions on Multilingual Low-Resource #NLProc funded by @Carlsbergfondet are now up! The project offers a lot of freedom in terms of research direction, and the conditions offered when doing a PhD in Denmark are hard to beat. Apply here: https://t.co/4FJdwS4A0A https://t.co/U48q4QUuNI\n"
          ]
        }
      ],
      "source": [
        "print(tweets[0][\"full_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeZ3HAr_gR_g"
      },
      "source": [
        "<a name=\"search_ops\"></a>\n",
        "### Search operators\n",
        "\n",
        "The are a number of search operators available, allowing for quite complex searches: [search operators](https://developer.twitter.com/en/docs/tweets/search/guides/standard-operators). Ignore the instructions on URL encoding the search string, *Twython* takes care of this for us.\n",
        "\n",
        "Search strings can be built up with multiple parameters. For example, to search for tweets from the *@LancasterUni* account mentioning *research*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE86yMV7gR_h",
        "outputId": "b0eb94d6-a41d-4d6f-f93b-c5c182fa3fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...3 tweets downloaded so far\n",
            "----\n",
            "Using smartphone apps could reveal your identity, according to research by our Dr Heather Shaw (@H_Shawberry)üì±üîç\n",
            "\n",
            "@PsychScience @lancspsychres @LancsUniSciTech\n",
            "\n",
            "https://t.co/KTq6c5EwsJ\n",
            "----\n",
            "RT @LancasterPress: AI generated faces are MORE trustworthy than real faces says research co-authored by Dr Sophie Nightingale @sjnightinga‚Ä¶\n",
            "----\n",
            "Drugs to increase insulin signaling may be effective for treating autism, according to research by @BLSLancasterUni's Dr Neil Dawson (@neilneuro)\n",
            "\n",
            "@RoyalSociety @LancasterUniFHM¬†\n",
            "\n",
            "https://t.co/7cilAGNKLa\n"
          ]
        }
      ],
      "source": [
        "tweets = search_twitter(twitter, \"from:LancasterUni research\", 10)\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOggLlZtgR_i"
      },
      "source": [
        "There are also different parameters available for the search request itself: [search parameters](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html).\n",
        "\n",
        "These can be passed through the search_twitter method (using [kwargs](https://book.pythontips.com/en/latest/args_and_kwargs.html)). For example, to restrict a search to only tweets in English:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSHtGJP2gR_j",
        "outputId": "23045963-e6f9-4253-c836-e102c9e22a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "RT @Thuggedraccoon: Microwaving fish is an office faux pas. I roast mine over an open flame in the bathroom\n",
            "----\n",
            "In the night light, do you still feel your pain?\n",
            "For the valor you waited, it never came\n",
            "If you were able, would you go change the past,\n",
            "To mend a faux pas with one last chance?\n",
            "----\n",
            "Yet another major IKN faux pas in visiting Russia at a very wrong time.\n",
            "Blind support by a few senior ex-FO officers puzzling.\n",
            "Wonder what rationale FO gave.\n",
            "The visit will further annoy US &amp; its NATO allies.  \n",
            "#PDM ought to condemn IKN as Parliament has not been consulted.\n",
            "----\n",
            "The Russia/Ukraine situation may represent Davos‚Äôs first faux pas. He simply can‚Äôt be beaten by any measure, which accounts for why every WEF Western power is dead set on bringing him down. The fact is ‚ÄòPutin is their only stumbling block to totalitarian world domination.\n",
            "----\n",
            "@bachus89 @MichealMartinTD Yes his visit to Hempel was a huge blunder. However Dev was held in very high regard by the Jewish community in Ireland even after this moral and diplomatic faux pas.\n",
            "----\n",
            "i am sorry for that i wore blue with green , I acknowledge that this faux pas has caused some people offence\n",
            "----\n",
            "RT @Gabbidon35: Still can‚Äôt believe the Baggies didn‚Äôt appoint Chris Wilder as manager. The biggest no brainer faux pas I‚Äôve seen in a long‚Ä¶\n",
            "----\n",
            "RT @Thuggedraccoon: Microwaving fish is an office faux pas. I roast mine over an open flame in the bathroom\n",
            "----\n",
            "RT @Thuggedraccoon: Microwaving fish is an office faux pas. I roast mine over an open flame in the bathroom\n",
            "----\n",
            "RT @Thuggedraccoon: Microwaving fish is an office faux pas. I roast mine over an open flame in the bathroom\n"
          ]
        }
      ],
      "source": [
        "tweets = search_twitter(twitter, \"\\\"faux pas\\\"\", 10, lang='en')\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNXumE4cgR_j"
      },
      "source": [
        "Try this with \"fr\", and without specifying the language to see the difference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAd2CEPpgR_k"
      },
      "source": [
        "<a name=\"outputting\"></a>\n",
        "## Outputting tweets\n",
        "\n",
        "To create a corpus for later use, you may want to save tweets to a file. A series of functions are provided below to output to JSON, plain text, and also to read in JSON saved tweets. Review and check your understanding of these functions. These are also provided in `tweets_json.py`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hDRMVAYgR_k"
      },
      "outputs": [],
      "source": [
        "def to_full_json(tweets, filepath=\"tweets.json\"):\n",
        "    \"\"\"Saves to filepath with the provided tweets with all attributes, in JSON.\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        #Dump json file. indent=4 prints the output prettier, but will increase disk space.\n",
        "        json.dump(tweets, f, indent=4)\n",
        "\n",
        "def to_minimal_json(tweets, filepath=\"tweets.json\"):\n",
        "    #This reduces each tweet to the set of keys (attributes) listed.\n",
        "    #Other attributes can be used here, see https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object\n",
        "    atts=['id_str', 'full_text']\n",
        "    minimal_tweets = [{k:tweet[k] for k in atts} for tweet in tweets]\n",
        "    with open(filepath, 'w') as f:\n",
        "        #Dump json file. indent=4 prints the output prettier, but will increase disk space.\n",
        "        json.dump(minimal_tweets, f, indent=4)\n",
        "\n",
        "def to_just_text(tweets, filepath=\"tweets.txt\"):\n",
        "    \"\"\"Saves to filepath with the provided tweets in plaintext, one tweet per line\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        for tweet in tweets:\n",
        "            #Linebreaks are replaced so we have one tweet per line.\n",
        "            f.write(\"{}\\n\".format(tweet['full_text'].replace(\"\\n\", \"  \").replace(\"\\r\", \"  \")))\n",
        "            \n",
        "def load_json_tweets(filepath):\n",
        "    \"\"\"Loads a JSON file into a list of tweet dictionary objects\"\"\"\n",
        "    tweets = json.load(open(filepath))\n",
        "    return tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yjwml_2gR_l"
      },
      "source": [
        "The full JSON can be saved, although note that this will take up some space. You can save to minimal JSON, and plain text by using the different functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALrjPPYcgR_l"
      },
      "outputs": [],
      "source": [
        "to_minimal_json(tweets, \"@LancasterUni-min.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2pLANPxgR_m"
      },
      "source": [
        "To load in previously saved tweets, just use load_json_tweets, as below, to load in the provided UCREL tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgYbgikEgR_m",
        "outputId": "1c97b001-a580-41fb-c7ec-66b2c34d9c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'created_at': 'Fri Aug 02 18:45:50 +0000 2019', 'id': 1157361882489065473, 'id_str': '1157361882489065473', 'full_text': \"And that's all folks. #acl2019nlp is over. It's been a great week, thanks to all the @ACL2019_Italy conference and workshop organisers. Goodbye Florence from the @UCREL_Lancaster #NLProc team https://t.co/lHhSARIKdW\", 'truncated': False, 'display_text_range': [0, 215], 'entities': {'hashtags': [{'text': 'acl2019nlp', 'indices': [22, 33]}, {'text': 'NLProc', 'indices': [179, 186]}], 'symbols': [], 'user_mentions': [{'screen_name': 'ACL2019_Italy', 'name': 'ACL2019', 'id': 1035524448319885312, 'id_str': '1035524448319885312', 'indices': [85, 99]}, {'screen_name': 'UCREL_Lancaster', 'name': 'UCRELResearchCentre', 'id': 1423596631, 'id_str': '1423596631', 'indices': [162, 178]}], 'urls': [{'url': 'https://t.co/lHhSARIKdW', 'expanded_url': 'https://twitter.com/DocElhaj/status/1156618784175734784?s=20', 'display_url': 'twitter.com/DocElhaj/statu‚Ä¶', 'indices': [192, 215]}]}, 'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>', 'in_reply_to_status_id': 1157187143447515136, 'in_reply_to_status_id_str': '1157187143447515136', 'in_reply_to_user_id': 1423596631, 'in_reply_to_user_id_str': '1423596631', 'in_reply_to_screen_name': 'UCREL_Lancaster', 'user': {'id': 1423596631, 'id_str': '1423596631', 'name': 'UCRELResearchCentre', 'screen_name': 'UCREL_Lancaster', 'location': 'Lancaster, UK.', 'description': 'Research centre for the study of corpus linguistics and corpus-based natural language processing at Lancaster University, UK.', 'url': 'http://t.co/2ErJcPTZz9', 'entities': {'url': {'urls': [{'url': 'http://t.co/2ErJcPTZz9', 'expanded_url': 'http://ucrel.lancs.ac.uk/', 'display_url': 'ucrel.lancs.ac.uk', 'indices': [0, 22]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 2226, 'friends_count': 264, 'listed_count': 51, 'created_at': 'Sun May 12 17:05:18 +0000 2013', 'favourites_count': 244, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 936, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '9AE4E8', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme16/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme16/bg.gif', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/3651470503/879f06f9a62c1fa2c41a427843506859_normal.png', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/3651470503/879f06f9a62c1fa2c41a427843506859_normal.png', 'profile_link_color': '0084B4', 'profile_sidebar_border_color': 'BDDCAD', 'profile_sidebar_fill_color': 'DDFFCC', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': True, 'quoted_status_id': 1156618784175734784, 'quoted_status_id_str': '1156618784175734784', 'quoted_status_permalink': {'url': 'https://t.co/lHhSARIKdW', 'expanded': 'https://twitter.com/DocElhaj/status/1156618784175734784?s=20', 'display': 'twitter.com/DocElhaj/statu‚Ä¶'}, 'quoted_status': {'created_at': 'Wed Jul 31 17:33:01 +0000 2019', 'id': 1156618784175734784, 'id_str': '1156618784175734784', 'full_text': 'Lancaster University team at #ACL2019nlp üáÆüáπ left to right: @DocElhaj @perayson @glorisonne @apmoore94 @Henrymossmoss @igezeani #NLProc üìö https://t.co/BDwjBqYHbJ', 'truncated': False, 'display_text_range': [0, 136], 'entities': {'hashtags': [{'text': 'ACL2019nlp', 'indices': [29, 40]}, {'text': 'NLProc', 'indices': [127, 134]}], 'symbols': [], 'user_mentions': [{'screen_name': 'DocElhaj', 'name': 'Dr Mahmoud El-Haj', 'id': 1325632296, 'id_str': '1325632296', 'indices': [59, 68]}, {'screen_name': 'perayson', 'name': 'Paul Rayson', 'id': 263108959, 'id_str': '263108959', 'indices': [69, 78]}, {'screen_name': 'glorisonne', 'name': 'Glorianna Jagfeld', 'id': 786546528278024192, 'id_str': '786546528278024192', 'indices': [79, 90]}, {'screen_name': 'apmoore94', 'name': 'Andrew Moore', 'id': 2603132052, 'id_str': '2603132052', 'indices': [91, 101]}, {'screen_name': 'Henrymossmoss', 'name': 'Henry Moss', 'id': 1007329796110635008, 'id_str': '1007329796110635008', 'indices': [102, 116]}, {'screen_name': 'igezeani', 'name': 'Ignatius Ezeani', 'id': 183198129, 'id_str': '183198129', 'indices': [117, 126]}], 'urls': [], 'media': [{'id': 1156618761727856641, 'id_str': '1156618761727856641', 'indices': [137, 160], 'media_url': 'http://pbs.twimg.com/media/EA0iosFXUAEadTK.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EA0iosFXUAEadTK.jpg', 'url': 'https://t.co/BDwjBqYHbJ', 'display_url': 'pic.twitter.com/BDwjBqYHbJ', 'expanded_url': 'https://twitter.com/DocElhaj/status/1156618784175734784/photo/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'large': {'w': 2048, 'h': 1152, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 675, 'resize': 'fit'}, 'small': {'w': 680, 'h': 383, 'resize': 'fit'}}, 'features': {'orig': {'faces': [{'x': 1204, 'y': 668, 'h': 72, 'w': 72}, {'x': 826, 'y': 404, 'h': 124, 'w': 124}, {'x': 538, 'y': 416, 'h': 126, 'w': 126}, {'x': 1138, 'y': 314, 'h': 140, 'w': 140}, {'x': 1490, 'y': 316, 'h': 152, 'w': 152}, {'x': 1834, 'y': 326, 'h': 130, 'w': 130}, {'x': 186, 'y': 334, 'h': 154, 'w': 154}]}, 'large': {'faces': [{'x': 1204, 'y': 668, 'h': 72, 'w': 72}, {'x': 826, 'y': 404, 'h': 124, 'w': 124}, {'x': 538, 'y': 416, 'h': 126, 'w': 126}, {'x': 1138, 'y': 314, 'h': 140, 'w': 140}, {'x': 1490, 'y': 316, 'h': 152, 'w': 152}, {'x': 1834, 'y': 326, 'h': 130, 'w': 130}, {'x': 186, 'y': 334, 'h': 154, 'w': 154}]}, 'medium': {'faces': [{'x': 705, 'y': 391, 'h': 42, 'w': 42}, {'x': 483, 'y': 236, 'h': 72, 'w': 72}, {'x': 315, 'y': 243, 'h': 73, 'w': 73}, {'x': 666, 'y': 183, 'h': 82, 'w': 82}, {'x': 873, 'y': 185, 'h': 89, 'w': 89}, {'x': 1074, 'y': 191, 'h': 76, 'w': 76}, {'x': 108, 'y': 195, 'h': 90, 'w': 90}]}, 'small': {'faces': [{'x': 399, 'y': 221, 'h': 23, 'w': 23}, {'x': 274, 'y': 134, 'h': 41, 'w': 41}, {'x': 178, 'y': 138, 'h': 41, 'w': 41}, {'x': 377, 'y': 104, 'h': 46, 'w': 46}, {'x': 494, 'y': 104, 'h': 50, 'w': 50}, {'x': 608, 'y': 108, 'h': 43, 'w': 43}, {'x': 61, 'y': 110, 'h': 51, 'w': 51}]}}}]}, 'extended_entities': {'media': [{'id': 1156618761727856641, 'id_str': '1156618761727856641', 'indices': [137, 160], 'media_url': 'http://pbs.twimg.com/media/EA0iosFXUAEadTK.jpg', 'media_url_https': 'https://pbs.twimg.com/media/EA0iosFXUAEadTK.jpg', 'url': 'https://t.co/BDwjBqYHbJ', 'display_url': 'pic.twitter.com/BDwjBqYHbJ', 'expanded_url': 'https://twitter.com/DocElhaj/status/1156618784175734784/photo/1', 'type': 'photo', 'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'}, 'large': {'w': 2048, 'h': 1152, 'resize': 'fit'}, 'medium': {'w': 1200, 'h': 675, 'resize': 'fit'}, 'small': {'w': 680, 'h': 383, 'resize': 'fit'}}, 'features': {'orig': {'faces': [{'x': 1204, 'y': 668, 'h': 72, 'w': 72}, {'x': 826, 'y': 404, 'h': 124, 'w': 124}, {'x': 538, 'y': 416, 'h': 126, 'w': 126}, {'x': 1138, 'y': 314, 'h': 140, 'w': 140}, {'x': 1490, 'y': 316, 'h': 152, 'w': 152}, {'x': 1834, 'y': 326, 'h': 130, 'w': 130}, {'x': 186, 'y': 334, 'h': 154, 'w': 154}]}, 'large': {'faces': [{'x': 1204, 'y': 668, 'h': 72, 'w': 72}, {'x': 826, 'y': 404, 'h': 124, 'w': 124}, {'x': 538, 'y': 416, 'h': 126, 'w': 126}, {'x': 1138, 'y': 314, 'h': 140, 'w': 140}, {'x': 1490, 'y': 316, 'h': 152, 'w': 152}, {'x': 1834, 'y': 326, 'h': 130, 'w': 130}, {'x': 186, 'y': 334, 'h': 154, 'w': 154}]}, 'medium': {'faces': [{'x': 705, 'y': 391, 'h': 42, 'w': 42}, {'x': 483, 'y': 236, 'h': 72, 'w': 72}, {'x': 315, 'y': 243, 'h': 73, 'w': 73}, {'x': 666, 'y': 183, 'h': 82, 'w': 82}, {'x': 873, 'y': 185, 'h': 89, 'w': 89}, {'x': 1074, 'y': 191, 'h': 76, 'w': 76}, {'x': 108, 'y': 195, 'h': 90, 'w': 90}]}, 'small': {'faces': [{'x': 399, 'y': 221, 'h': 23, 'w': 23}, {'x': 274, 'y': 134, 'h': 41, 'w': 41}, {'x': 178, 'y': 138, 'h': 41, 'w': 41}, {'x': 377, 'y': 104, 'h': 46, 'w': 46}, {'x': 494, 'y': 104, 'h': 50, 'w': 50}, {'x': 608, 'y': 108, 'h': 43, 'w': 43}, {'x': 61, 'y': 110, 'h': 51, 'w': 51}]}}}]}, 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 1325632296, 'id_str': '1325632296', 'name': 'Dr Mahmoud El-Haj', 'screen_name': 'DocElhaj', 'location': 'Lancaster, UK', 'description': 'NLP Lecturer at Lancaster University - Financial Narrative Processing, Arabic #NLProc, Machine Learning, MultiLingual Corpus & Computational Linguistics.', 'url': 'https://t.co/q26dOxwI96', 'entities': {'url': {'urls': [{'url': 'https://t.co/q26dOxwI96', 'expanded_url': 'http://www.lancs.ac.uk/staff/elhaj/', 'display_url': 'lancs.ac.uk/staff/elhaj/', 'indices': [0, 23]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 1718, 'friends_count': 310, 'listed_count': 22, 'created_at': 'Wed Apr 03 23:16:50 +0000 2013', 'favourites_count': 1372, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 923, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': '131516', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme14/bg.gif', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme14/bg.gif', 'profile_background_tile': True, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1206393320261521408/6jzhkWJR_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1206393320261521408/6jzhkWJR_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1325632296/1576461738', 'profile_link_color': '1B95E0', 'profile_sidebar_border_color': 'EEEEEE', 'profile_sidebar_fill_color': 'EFEFEF', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': False, 'default_profile_image': False, 'can_media_tag': True, 'followed_by': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 3, 'favorite_count': 21, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}, 'retweet_count': 2, 'favorite_count': 6, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}\n"
          ]
        }
      ],
      "source": [
        "ucrel_tweets = load_json_tweets(\"@UCREL_NLP-full.json\")\n",
        "print(ucrel_tweets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QI2CaTVgR_n"
      },
      "source": [
        "<a name=\"exercise\"></a>\n",
        "## Exercise\n",
        "\n",
        "Using the [list of attributes available](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object), produce a list of tweets (in JSON format or plain text, e.g. separated by a tab (TSV)) containing the time the tweet was written and the text. Of course, there are numerous ways the tweets could be outputted, e.g. into a database or a CSV file. Feel free to experiment with different outputs that might be useful to you. You can use the provided UCREL_NLP tweets(`@UCREL_NLP-full.json`) for this, or any other collection of tweets you have made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRfLXx_bgR_n"
      },
      "outputs": [],
      "source": [
        "# Exercise 1\n",
        "\n",
        "def to_tsv(tweets, filepath=\"tweets.tsv\"):\n",
        "    \"\"\"Saves to filepath with the provided tweets in plaintext, one tweet per line\"\"\"\n",
        "    with open(filepath, 'w') as f:\n",
        "        for tweet in tweets:\n",
        "            #Linebreaks are replaced so we have one tweet per line.\n",
        "            f.write(\"{}\\t{}\\n\".format(tweet['created_at'], tweet['full_text'].replace(\"\\n\", \"  \").replace(\"\\r\", \"  \")))\n",
        "\n",
        "ucrel_tweets = load_json_tweets(\"@UCREL_NLP-full.json\")\n",
        "to_tsv(ucrel_tweets, \"ucrel.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyCLptlWgR_p"
      },
      "source": [
        "<a name=\"tasks\"></a>\n",
        "## Further Tasks\n",
        "\n",
        "Come up with your own searches, and discuss with your neighbors. A few you can try:\n",
        "\n",
        "1. Find tweets mentioning *paper* and the *#NLProc* hashtag, which are not retweets.\n",
        "2. Find 10 positive tweets about *rain*, and 10 negative tweets about *rain*.\n",
        "3. Find Tweets to or from *@LancasterUni* mentioning *storm*, *wet* or *rain*.\n",
        "4. Find recent tweets mentioning *snow*.\n",
        "5. Find tweets mentioning *rain* from the Lancaster area.\n",
        "\n",
        "Also, think about what useful tweet attributes are available to output for the above searches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ywsCH4xgR_p",
        "outputId": "b596fbd4-5e65-4b67-e66e-6785480c49cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "Does anyone know when LREC paper notification will be? The website still says \"tbd\". https://t.co/Ep5gqZH6uf #NLProc\n",
            "----\n",
            "Kindly consider submitting your paper to the workshop on Language Technology and Resources for a Fair, Inclusive, and Safe Society at LREC. #LATERAISSE2022 #LREC2022 #NLProc #Bias #Equality #DiversityandInclusion\n",
            "----\n",
            "Having seen all these user-unfriendly paper submission systems, I'm just loving easychair more! Why NLP conferences don't go back to it?! #NLProc #easychair #torturedbyOpenreview\n",
            "----\n",
            "Great news! Recent @MetaAI work cited our work. It‚Äôs time to rearrange this work to submit #NLProc ü§®üôèü§ü check our paper here https://t.co/CjJjrgQOUo https://t.co/EKTXue7yWX\n",
            "----\n",
            "Don't have enough local language data?Leverage augmentation to improve your #NLProc performance. Paper \"Improving Short Text Classification through Global Augmentation Methods\" preprint https://t.co/uSXGL8G6JJ and library https://t.co/7IiGj3ECkE\n",
            "#MotherLanguageDay #AfricanNLP\n",
            "6/n\n"
          ]
        }
      ],
      "source": [
        "# 1. Find tweets mentioning paper and the #NLProc hashtag, which are not retweets.\n",
        "\n",
        "tweets = search_twitter(twitter, \"#NLProc paper -filter:retweets\", 5)\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])\n",
        "\n",
        "## note multiple search terms are always AND. use `OR` for either, or, both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJz7eag0gR_q",
        "outputId": "3cfc17b7-570a-433e-c843-5cb552aff578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "RT @_kness: ü¶ßI often get asked how I do it and what I use and are commissions open and all sorts of things. I love answering questions - es‚Ä¶\n",
            "----\n",
            "@Sefayildirim33 Biz de merakla bekliyoruz Sefa, bakalƒ±m gelecek g√ºnlerde neler olacak. :)\n",
            "----\n",
            "@Sefayildirim33 Adƒ± √ºst√ºnde diyorsun, Win yani :)\n",
            "----\n",
            "@jaempwiss00 hi rain, lets be moots! :D help rt like my pinned, ty! üòº\n",
            "----\n",
            "@Sefayildirim33 Ama en azƒ±ndan 1 tanesinin yeri senin i√ßin ayrƒ±dƒ±r? :)\n",
            "----\n",
            "ÿßŸÑÿßŸÜ ŸÅŸÇÿ∑ ÿ≥ÿ±€åÿßŸÑ Something in the rain ÿå ÿ¢ŸáŸÜ⁄Øÿ¥ Ÿà ÿÆŸàÿØ rain ÿ¨Ÿàÿßÿ®Ÿá :)\n",
            "----\n",
            "RT @kiioll100: Ïä§Ìã∞Ïª§ ÏàòÎüâÏ°∞ÏÇ¨!!!Ìèº (ÏûÖÍ∏àÌèº ÏïÑÎãòXXX) ~2/27ÍπåÏßÄ\n",
            "https://t.co/qSDFhbgh4F\n",
            "\n",
            "ÏàòÎüâÏ°∞ÏÇ¨Îüâ+a ÎßåÌÅº ÎØ∏Î¶¨ Ï†úÏûë ÌõÑ ÌåêÎß§Ìï† ÏòàÏ†ïÏù¥Ïó¨Ïöî\n",
            "Íº≠ Íµ¨Îß§ÌïòÏã§ Î∂ÑÎßå Ï∞∏Ïó¨Î∂ÄÌÉÅÎìúÎ†§Ïöî!! Í∞êÏÇ¨Ìï©ÎãàÎã§ :D https://‚Ä¶\n",
            "----\n",
            "Mam jebanych spredawczykow w klasie s tym jeden typ to ten z kt√≥rym by≈Çam w przyjacielskiej relacji w tamtym roku :))))\n",
            "----\n",
            "@AlphaTrilogy @DianaJunakovic This is beautiful! Loved the rain vibe! :)\n",
            "----\n",
            "@Sefayildirim33 Bug√ºn√ºn kuruyla 57.800 $ - 65.000 $ arasƒ±nda olabilir diyorsun yani? :)\n",
            "----\n",
            "RT @BTS_7roses: Indian ARMys dil me hi reh gaye, live streaming ki list me toh aaye hi nahi :((\n",
            "----\n",
            "Heavy Rain by PikaSempai is not rated yet. :( (77885499)\n",
            "----\n",
            "Sweet Rain‚ô™ÔΩÄ„ÄÅ„ÉΩÔΩÄ„ÄÅ„ÄÅ„ÉΩÔΩÄ„ÉΩL( ÔºæœâÔºæ )‚îòÔΩÄ„ÄÅ„ÉΩÔΩÄ„ÄÅ„ÄÅ„ÉΩÔΩÄ„ÉΩ‚ô™Èôç„Çä„Å†„Åó„ÅüÈõ®‚ô™ÔΩÄ„ÄÅ„ÉΩÔΩÄ„ÄÅ„ÄÅ„ÉΩÔΩÄ„ÉΩ‚îî( ÔºæœâÔºæ )„ÄçÔΩÄ„ÄÅ„ÉΩÔΩÄ„ÄÅ„ÄÅ„ÉΩÔΩÄ„ÉΩ‚ô™ÂÇò„Å™„Çì„Å¶‚ô™ÔΩÄ„ÄÅ„ÉΩÔΩÄ„ÄÅ„ÄÅ„ÉΩÔΩÄ„ÉΩL( ÔºæœâÔºæ )‚îòÔΩÄ„ÄÅ„ÉΩÔΩÄ„ÄÅ„ÄÅ„ÉΩÔΩÄ„ÉΩ‚ô™Âú∞ÈúáÔæÄÔæûÔΩßÔΩßÔΩßÔΩßÔΩßÔΩßÔΩ∞ÔΩ∞ÔΩ∞ÔΩ∞ÔΩ∞ÔΩØ‚ô™::((¬¥ÔæûÔæü'œâÔæü'))::‚ô™\n",
            "----\n",
            "@iam_areeba_ Sadloif i want it to rain :(\n",
            "----\n",
            "@rain_kkim I know right? It makes me sad too, mostly because I dont want us to become like other fandoms who start becoming more toxic as they grow :((\n",
            "----\n",
            "Freezing rain season is terrible :(\n",
            "----\n",
            "still in disbelief i‚Äôve finished ghost doctor already. i really love rain and kim bum‚Äôs chemistry :( gna miss them\n",
            "----\n",
            "@neljinn @kadygaetos Aw roach is missing rain. :(\n",
            "----\n",
            "@blueberrywoojin one of the reasons i don't like to argue with them is because most of them doesn't even try to listen and i also meant, the cubs arguing with other cubs too, it makes me sad seeing them argue, aren't we all supposed to help each other? :((\n",
            "----\n",
            "@sunrengokuu it‚Äôs been raining all week n will probs continue to rain :(((\n"
          ]
        }
      ],
      "source": [
        "#  2. Find 10 positive tweets about rain, and 10 negative tweets about rain.\n",
        "\n",
        "tweets = search_twitter(twitter, \"rain :)\", 10)\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])\n",
        "    \n",
        "tweets = search_twitter(twitter, \"rain :(\", 10)\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])\n",
        "\n",
        "# note, not convinced what Twitter is actually doing here with positive/negative, \n",
        "#seems to just return where an emoticon is used. Could use sentiment analysis as an alternative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGw7YM09gR_r",
        "outputId": "f4b4196d-87fb-4a10-abba-ee60333d556e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...4 tweets downloaded so far\n",
            "----\n",
            "@ianbakersson Looks wild, wet, and windy! Hope you all had a good reunion üëã ^David\n",
            "----\n",
            "@LancasterUni Sorry to hear about the damage done by the storm I hope no-one was hurt.  Just wondering if your offer holder open day still on tomorrow?\n",
            "----\n",
            "Update: Edward Roberts Court remains closed for the time being but all sections of the perimeter road have now reopened and campus remains open and operational. Please remain vigilant on campus and at home today during Storm Eunice\n",
            "----\n",
            "‚ö†Ô∏è Storm Eunice update\n",
            "\n",
            "Due to the wind affecting roofs on campus, Edward Roberts Court and a section of our perimeter road are currently closed.\n",
            "\n",
            "‚ÑπÔ∏è Our staff and students can find out more including any further updates on their Student Portal or Staff Intranet.\n"
          ]
        }
      ],
      "source": [
        "# 3. Find Tweets to or from @LancasterUni mentioning *storm, *wet* or *rain*.\n",
        "\n",
        "tweets = search_twitter(twitter, \"from:LancasterUni OR to:LancasterUni AND storm OR wet OR rain\", 10)\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])\n",
        "\n",
        "#note use of OR, ORs are done together, then AND'd with the from:LancasterUni\n",
        "# might not have any results, it did when I first did it! Could try different words, e.g. research"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMzjzfl-gR_r",
        "outputId": "5cc8d217-939f-4ae7-bbc8-c8b06e6a0c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "RT @RYOOO1515: „ÇÅ„Å£„Å°„ÇÉÈù¢ÁôΩ„ÅÑ„ÅóÊ•Ω„Åó„ÅÑ„Éñ„É©„Ç∂„Éº„Éì„Éº„Éàü§£\n",
            "Ëâ≤„ÄÖ„ÉÑ„ÉÉ„Ç≥„Éü„Å©„Åì„Çç„Åå„ÅÇ„ÇãSnow Man„ÅÆ„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÔºÅ„Å®„Å£„Å¶„ÇÇÂ•Ω„Åç„Å†„Éº„Éº\n",
            "#„Éñ„É©„Ç∂„Éº„Éì„Éº„Éà\n",
            "#„ÉÜ„É¨Êù±Èü≥Ê•ΩÁ•≠\n",
            "----\n",
            "Snow ManÂâ≤„Å®„Ç¨„ÉÉ„ÉÅ„Ç¨„ÉÅ„Å´Ë∏ä„ÇãÊõ≤„Å®„ÉÄ„É≥„Çπ„ÅåÂ§ö„Åã„Å£„Åü„Åã„Çâ„ÄÅ„Åì„Çå„Å†„ÅëÊ¥íËêΩ„ÅÆÂäπ„ÅÑ„ÅüÊõ≤„Åß„Å†„Åë„Å©„ÄÅ„Åó„ÇÅ„Çã„Å®„ÅìÁ∑†„ÇÅ„Å¶Ë∏ä„Çã„ÅÆÊú¨ÂΩì„Å´‚ÄúËâØ„ÅÑ‚Äù„Çì„Å†„Çà„Å™„ÅÅ„ÄÇÈÅä„Å≥„ÇíËÅû„Åã„Åõ„Åü‰∏≠„Å´Snow Man„ÅÆËâØ„Åï„Åå„Åó„Å£„Åã„ÇäÊª≤„ÅøÂá∫„Å¶„Çã„ÅÆ„ÅåÂ•Ω„Åç„Å†„Å™„ÅÅ„ÄÇ\n",
            "----\n",
            "RT @teretoongakusai: üå∏üå∏ü•≥#„ÉÜ„É¨Êù±Èü≥Ê•ΩÁ•≠ 2022Êò•üå∏üå∏\n",
            "Ôºº„ÉÜ„É¨„ÉìÊù±‰∫¨Á≥ª „Åü„Å†„ÅÑ„ÅæÊîæÈÄÅ‰∏≠‚ù£Ô∏èÔºè\n",
            "\n",
            "Snow Man „Åï„Çì„Åã„Çâ\n",
            "„Ç≥„É°„É≥„Éà„ÅÑ„Åü„Å†„Åç„Åæ„Åó„Åü‚ô™\n",
            "„Åì„ÅÆ„ÅÇ„Å®„ÄÅ„Åæ„ÇÇ„Å™„ÅèÁôªÂ†¥„Åß„Åôüëè\n",
            "\n",
            "#SnowMan\n",
            "#„Åä„ÅÜ„Å°„Åß„ÉÜ„É¨Êù±Èü≥Ê•ΩÁ•≠\n",
            "----\n",
            "‰∏ÄÊó¶Ê∑±ÂëºÂê∏„Åó„Çà„ÅÜ„ÄÅÂëºÂê∏„Åó„Å¶ÂëºÂê∏\n",
            "----\n",
            "Snow blind idiot out without her glasses.\n",
            "----\n",
            "Snow Man„Éñ„É©„Ç∂„Éº„Éì„Éº„ÉàÊúÄÈ´ò„Å†„Å£„ÅüÔºÅÔºÅ\n",
            "„Çπ„Éº„ÉÑ„Åø„Çì„Å™‰ººÂêà„Å£„Å¶„Çã„Åó„Çπ„Çø„Ç§„É´„Åø„Çì„Å™ËâØ„Åô„Åé„Å†„Åó„Åø„Çì„Å™ÂèØÊÑõ„Åã„Å£„Åü\n",
            "ÈòøÈÉ®„Åè„Çì„ÅÆÈ´™ÂûãÂ•Ω„Åç„Å†„Å™„Éº„Åä„Åß„Åì„Åã„Çè„ÅÑ„ÅÑ\n",
            "„Å®„ÅÑ„ÅÜ„ÅãÁøîÂ§™„ÇÇ„Åµ„Å£„Åã„ÇÇ„Åß„ÅìÂá∫„Åó„Çπ„Çø„Ç§„É´„ÅåÂ•Ω„Åç„Åß„Åô\n",
            "----\n",
            "RT @im_usa99b: „Éñ„É©„Ç∂„Éº„Éì„Éº„Éà„Åß„Éë„Éã„Éë„Éã„Åó„Å¶„Åü„Çâ„Çπ„Éé„Éû„Éã„Éì„É´„Åï„Çì„Åß2‰∏áÂàá„Å£„Å¶„Çã„Éºüò≥\n",
            "Snow ManÊØéÂõû„Éä„Ç§„Çπ„Çø„Ç§„Éü„É≥„Ç∞„Åß„Éü„É™„Ç™„É≥Ë°å„Åè„Çà„Å≠‚Ä¶„Åì„Çå„ÅØ„ÇÇ„Åó„Åã„Åó„Å¶Ôºü\n",
            "„Ç™„É™„Åï„Çì„Åß„ÇÇÂ£≤„Çå„Å¶„Çã„ÅóÔºÅ\n",
            "„Ç∑„É≥„Ç∞„É´HELLO HELLO„ÄÅSecret Touch„ÄÅKISSIN‚Äô MY‚Ä¶\n",
            "----\n",
            "Snow Man„ÄåÂèçËª¢„É°„Ç¨„ÉçÁéãÊ±∫ÂÆöÊà¶„ÄçÂÖ®„Å¶„ÅåÈÄÜ„Åï„Åæ„Å£„Å¶‚Ä¶„É†„É™ÔΩû!! https://t.co/lwAYKqhgD5 @YouTube„Çà„Çä\n",
            "----\n",
            "RT @ongaku_tv2nd: „ÉÜ„É¨„ÉìÂàùÊä´Èú≤\n",
            "\n",
            "Êò†Áîª„Äé„Åä„ÅùÊùæ„Åï„Çì„Äè‰∏ªÈ°åÊ≠å\n",
            "‚ô™„ÄÄ„Éñ„É©„Ç∂„Éº„Éì„Éº„Éà Ôºè Snow Man„ÄÄ‚ë†\n",
            "\n",
            "„ÉÜ„É¨Êù±Èü≥Ê•ΩÁ•≠\n",
            "#„Çπ„Éé„Éñ„É©„Ç∂„Éº https://t.co/DYPXbqjkqd\n",
            "----\n",
            "RT @SMC_Srinagar: Ongoing snow clearance in Islamyabal ward. https://t.co/naqBlrge1F\n"
          ]
        }
      ],
      "source": [
        "# 4. Find recent tweets mentioning snow.\n",
        "\n",
        "tweets = search_twitter(twitter, \"snow\", 10, result_type=\"recent\")\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])\n",
        "    \n",
        "# this is a search parameter, rather an operator in the search query string. Compare with \"popular\"\n",
        "# this is equivalent to 'latest' and 'top' on Twitter itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDmNs5L3gR_s",
        "outputId": "4fa3cd1c-07ef-4a40-9d2d-74833b00d6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            "Rain or shine (but mostly rain), @ucu is here! \n",
            "\n",
            "#OneOfUsAllOfUs #USSmess #USSmess https://t.co/6gRPDvqHNu\n",
            "----\n",
            "@rossi_tg Could do with a little bit of sun too. We have rain and floods over here in Manchester.\n",
            "----\n",
            "COURSE UPDATE - OPEN. Heritage 9 open. All on temporary greens. Another 8mm rain last night takes the total past 200mm for February, with over a week remaining. @JHorrocksPGA @Breightmetgc\n",
            "----\n",
            "@GaryBarlow @The_Lowry Enjoy hometown G ‚ù§üéπüé§\n",
            "&amp; stay safe in this wind &amp; rain!\n",
            "‚òîüå™üåÄüå¨‚òîüå´‚òîüå¨üåÄüå™‚òî https://t.co/fWsUYAk5EK\n",
            "----\n",
            "To help you stay safe behind the wheel ‚Äì truck or car ‚Äì read up on these top tips on road safety: https://t.co/I1MfRwhZ9k\n",
            "You‚Äôll find tips on:\n",
            "üëÅÔ∏è Daily walk round\n",
            "‚ùÑÔ∏è Driving in rain, fog, snow, ice\n",
            "‚úã Leaving space\n",
            "üí° Lights\n",
            "üõÅ Clean car\n",
            "ü©π Essentials to carry https://t.co/LHlJsvm1Kj\n",
            "----\n",
            "Just literally had to throw the cat outside (gently, obvs!), as she's spent the weekend staring daggers at me for causing wind and rain...\n",
            "----\n",
            "COURSE STATUS CLOSED. Another 20mm of rain plus high winds with storm Franklyn.\n",
            "----\n",
            "Coach Gunn is en route to #spring22camp4of9 at @SchoolWoodfield \n",
            "Rain &amp; wind won‚Äôt stop the FUN!!! https://t.co/vfbzlEt3iT\n",
            "----\n",
            "@nicmillerstale @curlywurlyfi The wind and rain have been horrendous, thus I am up. Interesting to see how high the pond is when it‚Äôs light.\n",
            "----\n",
            "@Lukesteele4 It‚Äôs exactly what @moorsforfuture have been doing. The hills around us are saturated to the point of not holding any more water. It‚Äôs been raining/snowing in Saddleworth since Wednesday and that after weeks of rain.\n"
          ]
        }
      ],
      "source": [
        "# 5. Find tweets mentioning rain from the Lancaster area.\n",
        "\n",
        "tweets = search_twitter(twitter, \"rain\", 10, geocode=\"54,-2.7,10mi\")\n",
        "for tweet in tweets:\n",
        "    print(\"----\")\n",
        "    print(tweet['full_text'])\n",
        "    \n",
        "# again, this is a search parameter, rather than part of search query string.\n",
        "# latitude, longitude, radius.\n",
        "# may need to set radius larger to get results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdrVdWHagR_t"
      },
      "source": [
        "<a name=\"advanced\"></a>\n",
        "## Optional advanced tasks\n",
        "\n",
        "\n",
        "The Twitter API provides access to further information about tweets, users, and plenty more. Here‚Äôs a list of things you can try if you have time. Please feel free to make other suggestions.\n",
        "\n",
        "1. Many other methods are available from Twython linked to Twitter API requests: https://twython.readthedocs.io/en/latest/api.html. One potentially useful task you should be able perform by adapting the available code is to collect the user details of a given account (see *show_user*).\n",
        "2. Expanding on 1., you could collect a list of users (e.g. a user's followers) and then collect all of their user information and tweets.\n",
        "3. You can use the Twitter Streaming API to collect tweets in real-time as they are posted. See the instructions for implementing this with Twython: https://twython.readthedocs.io/en/latest/usage/streaming_api.html, and attempt to collect all tweets mentioning a word of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVXUaBK7gR_u",
        "outputId": "57879845-5933-4cad-bf3d-c75e594aa82e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contributors_enabled': False,\n",
              " 'created_at': 'Fri Mar 20 15:35:26 +0000 2009',\n",
              " 'default_profile': False,\n",
              " 'default_profile_image': False,\n",
              " 'description': 'We‚Äôre a highly ranked collegiate university with a global reputation for teaching and research.',\n",
              " 'entities': {'description': {'urls': []},\n",
              "  'url': {'urls': [{'display_url': 'lancaster.ac.uk',\n",
              "     'expanded_url': 'http://www.lancaster.ac.uk',\n",
              "     'indices': [0, 23],\n",
              "     'url': 'https://t.co/tiy4EYH1rT'}]}},\n",
              " 'favourites_count': 15931,\n",
              " 'follow_request_sent': False,\n",
              " 'followers_count': 65056,\n",
              " 'following': False,\n",
              " 'friends_count': 1182,\n",
              " 'geo_enabled': True,\n",
              " 'has_extended_profile': False,\n",
              " 'id': 25521930,\n",
              " 'id_str': '25521930',\n",
              " 'is_translation_enabled': False,\n",
              " 'is_translator': False,\n",
              " 'lang': None,\n",
              " 'listed_count': 778,\n",
              " 'location': 'Lancaster, England',\n",
              " 'name': 'Lancaster University',\n",
              " 'notifications': False,\n",
              " 'profile_background_color': 'FFFFFF',\n",
              " 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              " 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              " 'profile_background_tile': False,\n",
              " 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/25521930/1628856423',\n",
              " 'profile_image_url': 'http://pbs.twimg.com/profile_images/878207781827903488/RLv3roLp_normal.jpg',\n",
              " 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/878207781827903488/RLv3roLp_normal.jpg',\n",
              " 'profile_link_color': 'B6121B',\n",
              " 'profile_location': None,\n",
              " 'profile_sidebar_border_color': 'FFFFFF',\n",
              " 'profile_sidebar_fill_color': 'FFFFFF',\n",
              " 'profile_text_color': '0A0101',\n",
              " 'profile_use_background_image': False,\n",
              " 'protected': False,\n",
              " 'screen_name': 'LancasterUni',\n",
              " 'status': {'contributors': None,\n",
              "  'coordinates': None,\n",
              "  'created_at': 'Tue Feb 22 13:44:01 +0000 2022',\n",
              "  'entities': {'hashtags': [],\n",
              "   'symbols': [],\n",
              "   'urls': [{'display_url': 'twitter.com/i/web/status/1‚Ä¶',\n",
              "     'expanded_url': 'https://twitter.com/i/web/status/1496118581712637961',\n",
              "     'indices': [113, 136],\n",
              "     'url': 'https://t.co/js3LTRo0uz'}],\n",
              "   'user_mentions': [{'id': 87503878,\n",
              "     'id_str': '87503878',\n",
              "     'indices': [96, 108],\n",
              "     'name': 'Dr Heather Shaw',\n",
              "     'screen_name': 'H_Shawberry'}]},\n",
              "  'favorite_count': 7,\n",
              "  'favorited': False,\n",
              "  'geo': None,\n",
              "  'id': 1496118581712637961,\n",
              "  'id_str': '1496118581712637961',\n",
              "  'in_reply_to_screen_name': None,\n",
              "  'in_reply_to_status_id': None,\n",
              "  'in_reply_to_status_id_str': None,\n",
              "  'in_reply_to_user_id': None,\n",
              "  'in_reply_to_user_id_str': None,\n",
              "  'is_quote_status': False,\n",
              "  'lang': 'en',\n",
              "  'place': None,\n",
              "  'possibly_sensitive': False,\n",
              "  'retweet_count': 4,\n",
              "  'retweeted': False,\n",
              "  'source': '<a href=\"http://www.falcon.io\" rel=\"nofollow\">Falcon Social Media Management </a>',\n",
              "  'text': 'Using smartphone apps could reveal your identity, according to research by our Dr Heather Shaw (@H_Shawberry)üì±üîç‚Ä¶ https://t.co/js3LTRo0uz',\n",
              "  'truncated': True},\n",
              " 'statuses_count': 27234,\n",
              " 'time_zone': None,\n",
              " 'translator_type': 'none',\n",
              " 'url': 'https://t.co/tiy4EYH1rT',\n",
              " 'utc_offset': None,\n",
              " 'verified': True,\n",
              " 'withheld_in_countries': []}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Advanced 1. Many other methods are available from Twython linked to Twitter API requests: https://twython.readthedocs.io/en/latest/api.html. One potentially useful task you should be able perform by adapting the available code is to collect the user details of a given account (see show_user).\n",
        "\n",
        "twitter.show_user(screen_name=\"LancasterUni\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4YFgdBJgR_v",
        "outputId": "c7cde0f0-ce6a-42c9-bbb3-2f1304f98712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LancasterBlack\n",
            "PETRASiot\n",
            "MattBradbury_\n",
            "_MichaelStead\n",
            "ProfWHollmann\n",
            "LUSoM_\n",
            "social_lu\n",
            "UBC\n",
            "LancasterNorth\n",
            "UnlockArchives\n"
          ]
        }
      ],
      "source": [
        "# Advanced 2 Expanding on 1., you could collect a list of users (e.g. a user's followers) and then collect all of their user information and tweets.\n",
        "\n",
        "following = twitter.get_friends_list(screen_name=\"LancasterUni\")\n",
        "followers = twitter.get_followers_list(screen_name=\"LancasterUni\")\n",
        "\n",
        "for f in following['users'][:10]:\n",
        "    print(f['screen_name'])\n",
        "    \n",
        "# could easily adapt above to get tweets too, using existing function above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aF8f4ZnhgR_w",
        "outputId": "c31821a2-a626-423c-b1d2-1845fbe0c773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "@NBCNews CCP (Chinese Communist party)Propaganda and spy‚Äôs is in the America boompoint_down_tone1flag_lr\n",
            "ËøôÊÆµËßÜÈ¢ëËß£Èáä‰∫Ü‰∏≠ÂÖ±Èó¥Ë∞çÂçï‰ºüÂÅ•Â¶Ç‰ΩïÊ∏óÈÄèÂà∞ÁæéÂõΩÈáëËûç‰ΩìÁ≥ª‰∏≠ÔºåÈÄöËøáÂêë‰∏≠ÂÖ±ÂÖ¨Âè∏Á≠πÈõÜÂíåÊäïËµÑÊï∞ÂçÉ‰∫øÁæéÂÖÉ...\n",
            "#shanweijian \n",
            "#ccpspy \n",
            "#ccpliedpeopledied \n",
            "#pensionfunds\n",
            "https://t.co/m63qXafz4R\n",
            "-----\n",
            "RT @xxaroundyou: ‡∏£‡∏≠‡∏£‡∏Ñ‡∏∑‡∏≠‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô lovely room, party room ‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤‡∏Å‡πá‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏° sfw, nsfw, romance, comedy, thriller, horror‚Ä¶\n",
            "-----\n",
            "RT @_john_gell: If Conservative MPs are in receipt of Russian money and the Conservative Party itself is dependant on Russian donations, ho‚Ä¶\n",
            "-----\n",
            "RT @BarrieCunning: Great to see  @Bill_Esterson interviewed by the wonderful @SophiaSleigh. The message is loud and clear the @UKLabour par‚Ä¶\n",
            "-----\n",
            "RT @ZionG38274521: I'm not really a birthday enthusiast, but Laycon's jam, New Dimension, is inspiring me to throw a party next month. That‚Ä¶\n",
            "-----\n",
            "@ScotTories anything to say about your party funding stream? How safe is Faslane if you're in Russia's pockets?\n",
            "-----\n",
            "RT @justinmadders: The point was well made- Russian money and influence goes right to the top of the Tory party\n",
            "-----\n",
            "@Naija102FM @EmmCee_RNB @beccablisse @Daddyshowkey Toss me party mood by azawi\n",
            "-----\n",
            "WHAAAAAAAAAT i loved this so much when i heard it i didn‚Äôt realise it was X\n",
            "-----\n",
            "@The_veenaD @amitmalviya @INCIndia @GauravPandhi @rohanrgupta @srivatsayb They did already\n",
            "-----\n",
            "RT @ReRead2021: Wow!! I wasn't expecting that truth bomb to be detonated on #BBCBreakfast mind!  Yes, of course the .@Conservatives Party w‚Ä¶\n",
            "-----\n",
            "RT @cquilty52: In a sliding doors scenario, this would've been the current UK cabinet, and the UK position on Ukraine.\n",
            "\n",
            "Which is much worse‚Ä¶\n",
            "-----\n",
            "@ScubaOfficial Off topic from the original tweet but the consensus is the same, it‚Äôs fucking hard to sustain a party in the current climate\n",
            "-----\n",
            "RT @nulasuchet: What price British democracy when a rich elite has the government‚Äôs ear? https://t.co/aLQEfQ24g7\n",
            "-----\n",
            "@paulmasonnews Paul the Tory Party are addicted to Russian money. Hence they hid the Russian report.\n",
            "-----\n",
            "RT @RejoinDave: This would be funny, if it really wasn't.\n",
            "-----\n",
            "RT @campbellclaret: My morning rant on the way Putin has played and bought the Tory Party over two decades and is now reaping the rewards.‚Ä¶\n",
            "-----\n",
            "@100pcLondoner @IainDale @MichaelLCrick You're a Tory. You don't take responsibility, and always seek to shift blame for your party's disastrous and incompetent decisions. So yes, you're equivocating. It's obvious. Laying the foundations for your future denials of culpability as you watch Brexit do its damage.\n",
            "-----\n",
            "RT @ProMaskOn: Chalo mein ja rahi hun ab. 7:30 ko bhi jana hai. \n",
            "\n",
            "Mein jitna bhi petition sign karu @kkundrra #KKundrraSquad k saath Khamba‚Ä¶\n",
            "-----\n",
            "Akavangata(money) kekatabude ebibina mu Uganda.\n",
            "\n",
            "But what I Know, no one can miss that cake or let it pass their mouth regardless of the party they are attached to.@kabuulwamuzafa2 ,@Sid_ug @NalmaLian @Ayandra256 .\n",
            "-----\n",
            "RT @SMTsyedAtifali: #Ÿæÿß⁄©ÿ≥ÿ™ÿßŸÜ_⁄©€å_ÿ¥ÿßŸÜ_⁄©Ÿæÿ™ÿßŸÜ\n",
            "Great visionary leader\n",
            "-----\n",
            "RT @jiyahmwohae: HI! I'm hosting a STREAMING PARTY AT SCENER. A CARAMELOVERSE (Carat+Melody+Universe) = other kband SETLIST! JOIN US! You j‚Ä¶\n",
            "-----\n",
            "RT @ApoorvaaTeenly: \" üëÜ\" for the candidate you want \n",
            "\"üñï\" for the party you hate \n",
            "#AssemblyElections2022\n",
            "-----\n",
            "RT @cloiecart: hii pls help us mine this set!!\n",
            "\n",
            "When: Thursday, 3pn\n",
            "Where: @Katzunnie\n",
            "Code: mine set for @cloiecart\n",
            "3rd party apps allowed!‚Ä¶\n",
            "-----\n",
            "RT @SodiqTade: I want to read APC boys reactions about Goodluck Jonathan. It is going to be funny to have a PDP man gets the APC ticket wit‚Ä¶\n",
            "-----\n",
            "RT @djrothkopf: I'm lying awake here tonight because I honestly can't fathom how we have gotten to the point that the leader of the GOP, th‚Ä¶\n",
            "-----\n",
            "RT @mikegalsworthy: Is it clear now why Russia has been so interested in Trump, Brexit and buying into Boris and the Conservative Party sin‚Ä¶\n",
            "-----\n",
            "RT @Elenaforever13: Progressives Are ‚ÄòLashing Out‚Äô At Dems Over Report That ‚ÄòSquad Politics‚Äô Is Hurting The Party‚Äôs Chances In The Midterms‚Ä¶\n",
            "-----\n",
            "RT @VaruKrutika: All protests are equal but some protests are more equal than others for media.\n",
            "-----\n",
            "RT @DidmusWaBarasa: Not true at all, Hon Musalia W Mudavadi is the  Party Leader of ANC, former Vice President\n",
            "and Minister of Finance at t‚Ä¶\n",
            "-----\n",
            "RT @tumuz_amon: Inviting a black person for any party or your wedding ceremony calls for alot...Be ready to be judged, negative compliments‚Ä¶\n",
            "-----\n",
            "RT @PippaCrerar: Boris Johnson urged cross-party to go further on sanctions/tackling Russian money.\n",
            "\n",
            "IDS: \"We need to hit them if we're goi‚Ä¶\n",
            "-----\n",
            "RT @liv_btob: Hello! I'll be hosting a watch party later at 1 AM PHT for Melozombies üòäüíô\n",
            "\n",
            "#BTOB\n",
            "#ÎÖ∏Îûò_The_Song\n",
            "@OFFICIALBTOB\n",
            " https://t.co/HMH‚Ä¶\n",
            "-----\n",
            "RT @ProMaskOn: Chalo mein ja rahi hun ab. 7:30 ko bhi jana hai. \n",
            "\n",
            "Mein jitna bhi petition sign karu @kkundrra #KKundrraSquad k saath Khamba‚Ä¶\n",
            "-----\n",
            "RT @aidso67: @squinteratn The road goes on forever and the party never ends üòÜüòÖüòÖ https://t.co/ZlocR58j9Y\n",
            "-----\n",
            "RT @INCIndia: Watch: Congress Party Briefing by Prof. @GouravVallabh at the AICC HQ.\n",
            " https://t.co/uqrIuyZq1S\n",
            "-----\n",
            "Another great article from @GeorgeMonbiot: https://t.co/GofGuHqrYX\n",
            "\n",
            "...and much as Scots might like to console themselves, saying, 'We didnae vote for the Tories...\" Oligarchs bring the wealth stolen from the Russian people into the UK using Scottish Limited Partnerships.\n",
            "-----\n",
            "RT @INCTamilNadu: Tamil Nadu Congress emerged as 3rd largest party in the state again in the Local body elections.\n",
            "FINAL RESULTS. \n",
            "#LocalBo‚Ä¶\n",
            "-----\n",
            "RT @harrisonjaime: Today, the defeated, twice-impeached former president is calling Vladimir Putin a ‚Äúgenius.‚Äù\n",
            "\n",
            "Why does the Republican Par‚Ä¶\n",
            "-----\n",
            "RT @GeffenRecords: Party, party yeah!\n",
            "-----\n",
            "Fun Bonus facts: Since about age 20 my actual political identity was never a party but \"anarchist\" when asked. That evolved to \"Ontalogical anarchist\" but as of February 2022 I am apparently also Conservative. I never saw that one coming as my beliefs have remained consistent\n",
            "-----\n",
            "RT @rohanduaT02: #UPElections2022 \n",
            "\n",
            "Our reporter @priyankaspeaks3 catches up with UP poll co-incharge @ianuragthakur during a hectic campai‚Ä¶\n",
            "-----\n",
            "RT @GerryHassan: As the Russia-Ukraine crisis deepens will the UK Tory Party be able to wean itself off of its dependency of dodgy Russian‚Ä¶\n",
            "-----\n",
            "RT @peterjukes: @TeamTurner18 @itfellup @carolecadwalla @aljwhite Sorry to repost this, but some people are only now waking up to it. The R‚Ä¶\n",
            "-----\n",
            "RT @BorisJohnson_MP: Our sanctions against Russia have two very clear aims - to maintain the flow of Russian cash into the Conservative Par‚Ä¶\n",
            "-----\n",
            "RT @VarierSangitha: üáÆüá≥Star Campaigner of @BJP4India ..But not in #BJP üòá\n",
            "No one else motivates our cadre as much as our Pappu does. \n",
            "We owe‚Ä¶\n",
            "-----\n",
            "RT @redflag3rd: @BolsheBarnacle @UKLabour The Lab party has been turned into a CESSPIT for Racist\n",
            "-----\n",
            "RT @milkymengs: Encouraging everyone to join the ongoing mass streaming party !! We need to close the gap between the opponents, We need to‚Ä¶\n",
            "-----\n",
            "RT @samanthamaiden: Still thinking about this. Imagine teaming up with some power-crazed local council to do this and sending out a newslet‚Ä¶\n",
            "-----\n",
            "RT @PDF53: The 'Party Questionairre' issued by the @metpoliceuk is NOT a standard one. It is tailored to each individual via Sue Grays Repo‚Ä¶\n",
            "-----\n",
            "RT @Clyde_Crasto: This action on Mr. Nawab Malik is nothing but pressure tactics to silence his voice.\n",
            "He was exposing the wrongdoings of s‚Ä¶\n",
            "-----\n",
            "RT @PaulTempleman6: Lubov Chernukhin has given ¬£1.9million to the Tory party. She is the wife of a former Russian minister. Not appearing o‚Ä¶\n",
            "-----\n",
            "RT @INCGujarat: Watch: Congress Party Briefing by Prof. @GouravVallabh at the AICC HQ.\n",
            "\n",
            "https://t.co/zYYYl6SfHo\n",
            "-----\n",
            "RT @von_anspach: What is it about the Conservative Party and Russia. Any ideas @pauljholmes?\n",
            "-----\n",
            "Spent most the morning getting lost down a murky Boris Johnson/KGB conspiracy tunnel because today I woke up and chose violence.\n",
            "-----\n",
            "RT @AsuraDeva1: Me and my best friend's wife having fun.. mean while her hubby came, what can he do after seeing my üçÜ in her.. after a few‚Ä¶\n",
            "-----\n",
            "RT @SAPisayWV: Missed the show? Don't worry because you'll be able to see the glitter in the sky and the glitter in our eyes again! üåü\n",
            "\n",
            "Levi‚Ä¶\n",
            "-----\n",
            "RT @jiyahmwohae: HI! I'm hosting a STREAMING PARTY AT SCENER. A CARAMELOVERSE (Carat+Melody+Universe) = other kband SETLIST! JOIN US! You j‚Ä¶\n",
            "-----\n",
            "RT @audubon3514: Bannon says ‚Äòwe‚Äôre in a war‚Äô to end the Democratic Party. Dems can‚Äôt dismiss his words. He played a key role in getting th‚Ä¶\n",
            "-----\n",
            "Sweet days\n",
            "-----\n",
            "RT @rupasubramanya: Can protest against government overreach in front of the Canadian consulate in NY but can‚Äôt do the same today in the he‚Ä¶\n",
            "-----\n",
            "RT @FPWellman: Another weasel who thinks we don‚Äôt know that the head of his party is cheering on the invasion. @LindseyGrahamSC you are on‚Ä¶\n",
            "-----\n",
            "@RatildaHoyden @RealCandaceO Yes the Democratic Party is corrupt they have been pushing for war with Russia since the Cold War. Ukraine isn‚Äôt worth American lives I‚Äôm sorry it may be to you but to me and the most of the US population could care less if Ukraine exists or not.\n",
            "-----\n",
            "RT @sreeramjvc: After the 2006 Assembly Elections the 3rd largest party was DMDK because they contested alone.\n",
            "After 2021 Assembly Election‚Ä¶\n",
            "-----\n",
            "and guess what? your carrot cake SUCKS! yeah! and at the last christmas party, you-...\n",
            "-----\n",
            "#MallannaSagar\n",
            "-----\n",
            "RT @rorybremner: BREAKING: Boris Johnson to hit Russia ‚Äòvery hard‚Äô by returning ¬£2m Russian donations to Tory Party and going to fewer of t‚Ä¶\n",
            "-----\n",
            "RT @sreeramjvc: BJP is the 3rd largest party in Tamizh Nadu. That‚Äôs it. Any debate on this is useless. Contesting in alliance &amp; claiming to‚Ä¶\n",
            "-----\n",
            "RT @megsymegs: Is Julie Bishop serious right now? We‚Äôve been screaming about this stuff for the near decade her party was in government and‚Ä¶\n",
            "-----\n",
            "RT @pripri_gosakto: Partylists not to vote for:\n",
            "\n",
            "Dumper\n",
            "Abono\n",
            "AAMBIS-OWA\n",
            "BH\n",
            "SAGIP\n",
            "TUCP\n",
            "PBA\n",
            "Abang-Lingkod\n",
            "1-PACMAN\n",
            "TINGOG\n",
            "Probinsyano Ako\n",
            "AC‚Ä¶\n",
            "-----\n",
            "RT @djrothkopf: I'm lying awake here tonight because I honestly can't fathom how we have gotten to the point that the leader of the GOP, th‚Ä¶\n",
            "-----\n",
            "@the_hindu Dignified person is behaving like a party's spokesperson\n",
            "-----\n",
            "@Er_ITMan Bmeen janata party\n",
            "-----\n",
            "@1mumrevolution She is a marvel! Publication party April at the @CuirtFestival\n",
            "-----\n",
            "RT @blackmailgirl: It's the weekend. That means it's party time #Sissy. Your #Blackmailer will take you to the party where you'll be strapp‚Ä¶\n",
            "-----\n",
            "RT @Jeffers0846: Someone mention Boris Johnski putting the son of a KGB General in the House of Lords üá∑üá∫ as well a Russian money swilling t‚Ä¶\n",
            "-----\n",
            "#NoTrustInTruss hopefully they‚Äôve shot them selves in the arse! If they have to stop donations from Russia, can they survive as a party? Who knows? This part is my favourite bit. Where the bad guys are revealed. Who is the mastermind? Who‚Äôs behind the mask? https://t.co/wS76AG4w5p\n",
            "-----\n",
            "RT @magulangsofanji: Please use Anji‚Äôs default tags when tweeting. \n",
            "\n",
            "We don‚Äôt have a twitter party today so everyone can take a rest; catch‚Ä¶\n",
            "-----\n",
            "RT @ashoswai: Hindu Right Wing regime's youth wing chief declares his party's victory by getting 1.46% of votes in Tamil Nadu. His Leader h‚Ä¶\n",
            "-----\n",
            "I can name 10 party presidents of BJP in the last couple of decades who desperately wanted to become Prime Minister of India but then we have Cong whose President stepped aside and choose the most eligible person to cleanse the disastrous handling of govt by Atal Bihari Vajpayee.\n",
            "-----\n",
            "RT @Britain_People: #SANCTIONS Russia \n",
            "\n",
            "Is that it?\n",
            " \n",
            "‚óæÔ∏èONLY sanctioning 5 banks and 3 oligarchs \n",
            "\n",
            "Suggests Government cares more about pro‚Ä¶\n",
            "-----\n",
            "RT @openDemocracy: \"The Electoral Commission is only the latest target in the Tory party‚Äôs determination to destroy any semblance of scruti‚Ä¶\n",
            "-----\n",
            "Murdo here, whose party brought us Brexit and is funded by Russian money\n",
            "-----\n",
            "RT @CursedSe7en: @InderSarai Bhai AAP kahan thi Punjab mein? Drugs ka bahot asar hai Punjab mein need a party to stop that drug flow not fl‚Ä¶\n",
            "-----\n",
            "RT @zhjl7: plagiarism: presenting someone else's ideas as your own.\n",
            "\n",
            "gatekeeping: to limit another party's participation in a collective ac‚Ä¶\n",
            "-----\n",
            "RT @viveknairp: Why a patriotic Indian should never vote for the Congress Party? Below is the answer by Sayan Mukherjee on Quora. https://t‚Ä¶\n",
            "-----\n",
            "RT @DanielaNadj: Boris Johnson might be hoping that a Russia/Ukraine conflict will draw attention away from partygate, but ironically enoug‚Ä¶\n",
            "-----\n",
            "RT @STET_MERIT_2019: @yuvahallabol @bihar_police @NitishKumar @BiharTakChannel @Architguptajii Ye opportunist halla bol party baba saheb ka‚Ä¶\n",
            "-----\n",
            "RT @AbiyAhmedAli: This morning we have began Prosperity Party‚Äôs executive committee meeting to discuss key national as well as party agenda‚Ä¶\n",
            "-----\n",
            "@RepJeffries The McQuade Memo to the DOJ is what is going to happen to DJT &amp; his crony portion of the Republican Party.  The Republican platform will not be moving ahead with any Trump agenda.\n",
            "-----\n",
            "RT @paulmasonnews: If it gets really bad I might sanctions the ones I party with ...\n",
            "-----\n",
            "RT @ImIncorrigible: Ian Hislop: \"The Tory party is almost entirely funded by Russian oligarchs most of whom are already sanctioned\"\n",
            "\n",
            "#r4tod‚Ä¶\n",
            "-----\n",
            "Wherever in the world we show up, stadium party ay\n",
            "Born as a K-pop idol, an artist who reincarnated\"\n",
            "..........\n",
            "\n",
            "\"Whether I‚Äôm an idol or an artist doesn‚Äôt matter, cheers\"\n",
            ".......\n",
            "\n",
            "\"Breaking a new record is a race with myself, a race, yeah\"\n",
            "\n",
            "https://t.co/dL8cWIgplt \n",
            "\n",
            "#Dionysus https://t.co/Ecr8jy3puu\n",
            "-----\n",
            "RT @raemyne: Thankles for the tag @InfiniteRichter\n",
            "\n",
            "THIS OR THAT VTUBER TIME\n",
            "üê∏ 2D &gt; 3D\n",
            "üê∏ CHAOS &gt; Structure\n",
            "üê∏ Seiso = Lewd\n",
            "üê∏ Couple Pics = S‚Ä¶\n",
            "-----\n",
            "RT @magulangsofanji: Please use Anji‚Äôs default tags when tweeting. \n",
            "\n",
            "We don‚Äôt have a twitter party today so everyone can take a rest; catch‚Ä¶\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-87e4ce690d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyStreamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsumer_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumer_secret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccess_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatuses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"party\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twython/streaming/types.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://stream.twitter.com/%s/statuses/filter.json'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m               \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/twython/streaming/api.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, url, method, params)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36miter_lines\u001b[0;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0mpending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_unicode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_unicode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpending\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_chunk_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Advanced 3 You can use the Twitter Streaming API to collect tweets in real-time as they are posted. See the instructions for implementing this with Twython: https://twython.readthedocs.io/en/latest/usage/streaming_api.html, and attempt to collect all tweets mentioning a word of interest.\n",
        "\n",
        "from twython import TwythonStreamer\n",
        "\n",
        "class MyStreamer(TwythonStreamer):\n",
        "    def on_success(self, data):\n",
        "        if 'extended_tweet' in data:\n",
        "            text = data['extended_tweet']['full_text']\n",
        "        else:\n",
        "            text = data['text']\n",
        "\n",
        "        print(\"-----\")\n",
        "        print(text)\n",
        "\n",
        "    def on_error(self, status_code, data):\n",
        "        print(status_code)\n",
        "        \n",
        "stream = MyStreamer(consumer_key, consumer_secret, access_token, access_secret)\n",
        "stream.statuses.filter(track=\"party\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m76o2qLDgR_w"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "413_wk16_Twitter_answers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}