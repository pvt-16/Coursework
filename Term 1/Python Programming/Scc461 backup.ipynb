{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Scc461 backup.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHrwNgz9gpCKHR8ZH131wl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fu8cGsTcpZ3M"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","\"\"\"scc 461 py Decision tree.ipynb\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1TP0t-pgIZHf4D4KUvhtD6T5ZXhMAtmrQ\n","\n","## Basics\n","\"\"\"\n","\n","from sklearn import datasets\n","from sklearn import model_selection\n","import pandas as pd\n","import warnings\n","#from sklearn.tree import DecisionTreeClassifier\n","import time \n","import matplotlib.pyplot as plt\n","import graphviz\n","from enum import Enum\n","\n","warnings.filterwarnings('ignore')\n","\n","class NodeTypes(Enum):\n","  LEAF = \"Leaf\"\n","  PARENT = \"Parent\"\n","  ROOT = \"Root\"\n","\n","wineDataset = datasets.load_wine()\n","\n","featureSet, targetSet = wineDataset.data, wineDataset.target\n","\n","dfFeatures = pd.DataFrame(featureSet, columns = wineDataset.feature_names)\n","dfTarget = pd.DataFrame(targetSet, columns = [\"Class\"])\n","\n","\"\"\"## EDA\"\"\"\n","\n","dfFeatures.head()\n","\n","dfFeatures.info()\n","\n","print(len(dfTarget['Class'].value_counts()))\n","\n","\"\"\"## Feature Engineering\n","\n","### Handle Categorical variables\n","\n","encoding\n","\n","Ref: https://www.kaggle.com/prashant111/decision-tree-classifier-tutorial#12.-Feature-Engineering-\n","\"\"\"\n","\n","#import category_encoders as ce\n","\n","\"\"\"## Train and Test datasets\"\"\"\n","\n","import sklearn as skl\n","from sklearn import tree\n","\n","trainFeatureSet, testFeatureSet, trainTargetSet, testTargetSet = model_selection.train_test_split(dfFeatures, dfTarget,\n","                                                                                                      train_size = 0.7, test_size = 0.3,\n","                                                                                                      shuffle = True)\n","\n","\"\"\"## Helper methods\"\"\"\n","\n","def getEvaluationMetrics(predictedTargetSet): \n","  accuracy = skl.metrics.accuracy_score(testTargetSet, predictedTargetSet)\n","  precision = skl.metrics.precision_score(testTargetSet, predictedTargetSet, average='micro')\n","  recall = skl.metrics.recall_score(testTargetSet, predictedTargetSet, average='micro')\n","  f1score = skl.metrics.f1_score(testTargetSet, predictedTargetSet, average='micro')\n","  classificationReport = skl.metrics.classification_report(testTargetSet, predictedTargetSet)\n","  return {\n","      accuracy: accuracy,\n","      precision: precision,\n","      recall: recall,\n","      f1score: f1score,\n","      classificationReport: classificationReport\n","  }\n","\n","def printEvaluationMetrics(predictedTargetSet):\n","  evalMetrics = getEvaluationMetrics(predictedTargetSet)\n","  print (evalMetrics)\n","  print(f\"Accuracy score of model: {evalMetrics.accuracy}\")\n","  print(f\"Precision score of model: {evalMetrics.precision}\")\n","  print(f\"Recall score of model: {evalMetrics.recall}\")\n","  print(f\"F1 of model: {evalMetrics.f1score}\")\n","  print(f\"Classification report of model: {evalMetrics.classificationReport}\")\n","\n","def getTimeTaken(startTime, endTime):\n","  return round((endTime - startTime) * 100, 5)\n","\n","def getTrainingPerformanceMetrics():\n","  return {\n","      timeTaken: timeTaken\n","  }\n","\n","def getAverage(a, b):\n","    #lambda x, y: (x[colIndex]+y[colIndex])/2\n","    return (a+b)/2\n","\"\"\"## Decision Tree\n","\n","### Helper methods for Decision tree\n","\"\"\"\n","\n","#@title\n","#Calculation of gini value\n","def giniValue(localtrainingSet) -> float:\n","  giniValue = sumOfProbabilities = 0 \n","  #print(localtrainingSet)\n","  classes = localtrainingSet[\"Class\"].unique()\n","\n","  if len(classes)>2:\n","    for i in range(classes):\n","      localTreeClass = filter(localtrainingSet, lambda row: row[\"Class\"] == classes[i]) #Filter for each class\n","      sumOfProbabilities+= (len(localTreeClass) / len(tree)) ** 2 \n","    giniValue = 1 - sumOfProbabilities\n","  return giniValue #return the Gini Index value for this split\n","  #return False\n","\n","#find the best partition that minimizes the Gini index:\n","def getGiniIndexValue( splitPoints: list, colIndex: int, dataset) -> tuple(): #returns tuple with (Gini index value, the split value)\n","  localLeftTree = localRightTree = [] = giniIndexes = []\n","  colName = dataset.columns[colIndex]\n","  for midVal in splitPoints:\n","      localLeftTree = dataset.loc[dataset[colName] <= midVal] #list(filter(lambda x: x <= midVal, dataset))\n","      localRightTree = dataset.loc[dataset[colName] > midVal] #list(filter(lambda x: x > midVal, dataset))\n","      \n","      D1 = len(localLeftTree); D2 = len(localRightTree); D = len(dataset)\n","\n","      if D >0:        #weighted average of gini impurities\n","          localGiniImpurity = ( (D1/ D) * (giniValue(localLeftTree)) + (D2/ D) * (giniValue(localRightTree)))\n","          giniIndexes.append((localGiniImpurity, midVal))\n","\n","  if len(giniIndexes) > 0 :\n","      return sorted(giniIndexes)[0]# returns the tuple with the smallest gini index value\n","  \n","  return False #Split could not be determined\n","\n","#@title\n","# from sklearn.tree import _tree\n","\n","# def tree_to_code(tree, feature_names):\n","#     tree_ = tree.tree_\n","#     feature_name = [\n","#         feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n","#         for i in tree_.feature\n","#     ]\n","#     print \"def tree({}):\".format(\", \".join(feature_names))\n","\n","#     def recurse(node, depth):\n","#         indent = \"  \" * depth\n","#         if tree_.feature[node] != _tree.TREE_UNDEFINED:\n","#             name = feature_name[node]\n","#             threshold = tree_.threshold[node]\n","#             print \"{}if {} <= {}:\".format(indent, name, threshold)\n","#             recurse(tree_.children_left[node], depth + 1)\n","#             print \"{}else:  # if {} > {}\".format(indent, name, threshold)\n","#             recurse(tree_.children_right[node], depth + 1)\n","#         else:\n","#             print \"{}return {}\".format(indent, tree_.value[node])\n","\n","#     recurse(0, 1)\n","\n","#@title\n","def prechecksOnDataSet(dataSet):\n","\n","  if len(dataSet['Class'].value_counts()) <2: #Atleast 2 classes in the target\n","    return False\n","  return True\n","\n","\"\"\"### Helper Classes\"\"\"\n","\n","class Node:  #class definition\n","    def __init__(self, feature, splitValue, testCriteria, left=None, right=None):  \n","        #Question - column, value\n","        self.feature = feature\n","        self.testCriteria = testCriteria\n","        self.splitValue = splitValue \n","        self.nodeType = None # (Root, parent, child) \n","        self.left = left\n","        self.right = right\n","\n","class LocalNode(Node): \n","    def __init__(self, gini, feature, splitValue, testCriteria):\n","      Node.__init__(self, feature, splitValue, testCriteria)  \n","      self.gini = gini\n","\n","class Tree:\n","  def __init__(self, rootNode: Node = None):\n","    self.root = rootNode\n","\n","trainFeatureSet[\"alcohol\"].dtype.name\n","\n","\"\"\"### Decision Tree\"\"\"\n","\n","#@title\n","class DecisionTree:     #Declaring DecisionTree\n","  #Constructor\n","  def __init__(self, criterion: str = \"gini\", maxDepth: int = None) -> None:\n","    self.criterion = criterion\n","    self.maxDepth = maxDepth\n","    self.dfFeatures = 0\n","    self.dfTarget = 0\n","    self.tree = Tree() #Set of rules for our model\n","\n","  def modelFit(self, featureSet, targetSet):\n","    self.dfFeature = featureSet\n","    self.dfTarget = targetSet\n","\n","    if (prechecksOnDataSet(targetSet)):\n","      self._train(featureSet.join(targetSet))\n","\n","  def _train(self, trainingSet):\n","    self.Tree = Tree(self._findBestSplit(trainingSet))\n","\n","  def _findBestSplit(self, trainingSet) -> tuple():\n","    gini = split = 0\n","    leftTree = rightTree = []\n","    listOfAllColsAndGini = []\n","\n","    for colIndex in range(len(trainingSet.columns)-1):\n","      splitPoints = []\n","      sortedData = trainingSet.copy()\n","      columnData = trainingSet.iloc[:,colIndex]\n","      columnType = trainingSet.iloc[:,colIndex].dtype.name\n","      columnName = trainingSet.columns[colIndex]\n","      if (columnType == \"float64\" or  columnType == \"float64\" ): # continuous integer features, sort it in ascending order \n","        columnData = sortedData.sort_values(by=columnName) #.iloc[:,colIndex]\n","        \n","        if (columnData.shape[0] < 200):\n","            for i in range(columnData.shape[0] -1):\n","                splitPoints.append( (columnData.iloc[i, colIndex] + columnData.iloc[i+1, colIndex])/2)\n","          #splitPoints = list(map(getAverage, columnData[:-1], columnData[1:])) #midpoints are the splitpoints \n","        #else:\n","          #splitPoints = list(filter( lambda m: m not in list(map(lambda y: y[0], sortedData)), midpoints)) #different splitpoints to optimize\n","\n","        #columnData = sortedData\n","        if len(splitPoints) == 0:\n","          continue;\n","      elif columnType == \"category\":\n","        continue;\n","      else:\n","        continue\n","\n","      #Get Gini Index value and the split point value\n","      giniIndexVal= getGiniIndexValue(splitPoints, colIndex, columnData)\n","      if giniIndexVal == False:\n","          continue;\n","\n","      gini, split = giniIndexVal\n","      gini = round(gini, 5)   \n","      node = LocalNode(gini = gini, feature= dfFeatures.columns[colIndex], splitValue= split, testCriteria=\"<=\")\n","      listOfAllColsAndGini.append(node)\n","\n","    #We use the split point value calculated to get the left and right branches of the decision tree\n","    bestNode = sorted(listOfAllColsAndGini)[0]\n","    parentNode= Node(bestNode[\"feature\"], )\n","    leftTree = list(filter( lambda x:  x[colIndex] <= split, sortedData))\n","    rightTree = list(filter( lambda x:  x[colIndex] > split, sortedData))\n","  \n","    return (gini, split, leftTree, rightTree)\n","\n","dTreeOrg = DecisionTree()\n","\n","dTreeOrg.modelFit(dfFeatures, dfTarget)\n","\n","# def _giniValue(self, tree: DataFrame) -> float:\n","  #   giniValue =  sumOfProbabilities = 0 \n","  #   classes = self.dfTarget.Class.unique()\n","\n","  #   if len(tree)>0:\n","  #     for i in range(classes):\n","  #       localTreeClass = filter(tree) #Filter for each class\n","  #       sumOfProbabilities+= (len(localTreeClass) / len(tree)) ** 2 \n","  #     giniValue = 1 - sumOfProbabilities\n","  #     return giniValue #return the Gini Index value for this split\n","  #   return False\n","\n","# =============================================================================\n","# \"\"\"## sklearn Decision tree\n","# \n","# \"\"\"\n","# \n","# dTreeSkl = tree.DecisionTreeClassifier(criterion='gini', random_state=0) #max_depth=3,\n","# \n","# \"\"\"### Train model\"\"\"\n","# \n","# dTreeSklStartTime = time.time()\n","# dTreeSkl.fit(trainFeatureSet, trainTargetSet)\n","# dTreeSklEndTime = time.time()\n","# dTreeSklTimeTaken = getTimeTaken(dTreeSklStartTime, dTreeSklEndTime) \n","# \n","# print(f\"Time taken to train Decision Tree:\", dTreeSklTimeTaken)\n","# \n","# \n","# \n","# \"\"\"### Test model\"\"\"\n","# \n","# predictedValues = dTreeSkl.predict(testFeatureSet)\n","# print(f\"Evaluation Metrics:\", getEvaluationMetrics(predictedTargetSet = predictedValues))\n","# \n","# #trainTargetSet\n","# skl.metrics.accuracy_score(dTreeSkl.predict(trainFeatureSet), trainTargetSet)\n","# \n","# \"\"\"### Visualizing\"\"\"\n","# \n","# #@title\n","# \n","# dot_data = skl.tree.export_graphviz(dTreeSkl, out_file=None,  \n","#                 filled=True, rounded=False,\n","#                 special_characters=True,\n","#                 feature_names = wineDataset.feature_names,\n","#                 class_names = wineDataset.target_names)\n","# graph = graphviz.Source(dot_data)  \n","# graph\n","# =============================================================================\n","\n","\"\"\"## Chefboost\"\"\"\n","\n","# pip install chefboost\n","\n","# from chefboost import Chefboost as chef\n","\n","# df = dfFeatures.join(dfTarget)\n","# config = {'algorithm': 'CART'} #Algo selection \n","# #Other options for classification- CART, C4.5, CHAID, ID3,\n","# df['Class'] = df['Class'].astype(object) #requires 'Decision'/ Label column to be object dtype\n","\n","# model2 = chef.fit(df, config = config, target_label = 'Class')\n","\n","# prediction = chef.predict(model2, param = testFeatureSet.to_numpy())\n","\n","# testFeatureSet.to_numpy()[0,12] <=746.8932584269663\n","\n","# \"\"\"# Rough notes (Ignore)\"\"\"\n","\n","# trainFeatureSet.corr()"]}]}