{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"D AI coursework 1.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPMMBDRV2vu2OXZ8ma5VHNY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Q2. how many iterations"],"metadata":{"id":"27axffq3f_qt"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"siytZ_WCfA8A"},"outputs":[],"source":["# def howManyIterations(x, epsilon): #return number of iterations taken to reach value less than epsilon\n","#     count =0\n","#     errorVal =x\n","#     if errorVal < epsilon or x>= 0.5 : #Schapire's graph -we only consider x<0.5\n","#         return False\n","\n","#     while (errorVal > epsilon):\n","#         count = count+1 #counter \n","#         x = errorVal #the calculated value is the new x valye\n","#         errorVal = (3*x*x - (2*x*x*x))  #Equation for error as shown by Schapire\n","#     return count #Total number of iterations\n","    \n","# x = 0.4\n","# epsilon = 0.2\n","# print(howManyIterations(x,epsilon))\n"]},{"cell_type":"markdown","source":["### q4. Weak Classifier"],"metadata":{"id":"bCi4CJv8gFob"}},{"cell_type":"code","source":["# A fake Weak Classifier for SCC462 Assignment.\n","# Leandro Soriano Marcolino\n","\n","import random\n","\n","class WeakClassifier:\n","\n","    def __init__(self):\n","        self._predictedLabels = []\n","    \n","    def train(self, dataset, labels, p):\n","        # We are simulating a training process here, this is not a real classifier.       \n","        self._predictedLabels = [0]*len(labels)\n","\n","        for n in range(len(labels)):\n","            r = random.random()\n","\n","            # Let's pretend odd items are harder\n","            if (n % 2 == 0):\n","                correctProb = 0.6\n","            else:\n","                correctProb = 0.55\n","            \n","            if (r < correctProb):\n","                self._predictedLabels[n] = labels[n]\n","            else:\n","                self._predictedLabels[n] = (1 - labels[n])\n","\n","    def classify(self, item):        \n","        return self._predictedLabels[item]\n","\n","class AdaBoost(WeakClassifier):\n","    def __init__(self):\n","        super().__init__()\n","    def train(self, dataset, labels, D, T):\n","        return\n","    def classify(self, item):\n","        return super().classify(item)\n","\n","random.seed(0)\n","labels = [0, 1, 1, 1, 1, 0]\n","dataset = [[1,2],[3,4],[5,6],[7,8],[9,10],[11,12]]\n","D = [1/6]*6\n","adaBoost = AdaBoost()\n","adaBoost.train(dataset,labels,D,3)\n","\n","for n in range(len(dataset)):\n","    print(adaBoost.classify(n), end=\" \")\n","\n","#0 0 1 0 1 0"],"metadata":{"id":"ARYuKDoIgFK3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### q7. Stacked generalization"],"metadata":{"id":"i7rtjIoLRjvR"}},{"cell_type":"code","source":["# Simple Logistic Regression classifier for SCC462 Assignment. Adapted from solution of SCC461 CW 10.\n","# Leandro Soriano Marcolino\n","\n","from itertools import count\n","import random\n","import math\n","from typing import List\n","\n","class LogisticRegression:\n","    # Initialise learning rate (alpha), threshold and weights\n","    def __init__(self, nFeatures, alpha = 0.15, threshold = 0.5, nEpochs = 200):\n","        self._alpha = alpha\n","        self._nFeatures = nFeatures\n","        self._weights = []\n","        self._threshold = threshold\n","        self._nEpochs = nEpochs\n","        \n","    # Calculates the output of the logistic regression. Note that we do not round here.\n","    def _logistic(self, item):\n","        t = 0\n","        for w in range(len(self._weights)): # We use a for loop for the linear combination, to be more general to any number of features\n","            t += item[w]*self._weights[w]\n","        return 1/(1 + math.exp(-t)) # Math.exp is the natural exponential function (e^x)\n","        \n","    def train(self, dataset, labels):\n","        # Initialising weights\n","        self._weights = [random.random()]*(self._nFeatures+1)\n","        \n","        # Pre-initialising the lists\n","        dataWithLabels = [0]*len(dataset)\n","        MSEList = [0]*self._nEpochs\n","            \n","        # We combine the dataset with the labels, so that we can shuffle without losing the label information\n","        for i in range(len(dataset)):\n","            dataWithLabels[i] = dataset[i] + [labels[i]]\n","\n","        # Shuffle changes the list, so we make a copy of it first\n","        newData = dataWithLabels.copy()\n","\n","        for epoch in range(self._nEpochs):\n","            # The dataset is randomly shuffled at the beginning of each epoch\n","            random.shuffle(newData)\n","\n","            #import ipdb; ipdb.set_trace()\n","            \n","            # For each epoch, we need to keep track of the MSE\n","            error = 0\n","            \n","            for item in newData:\n","                item = [1] + item # We add a 1 to the beginning of each item, to account for the independent term\n","                sigma = self._logistic(item[:-1]) # Now item also has the label in the end, so need to adjust when passing to the logistic function\n","\n","                # Similarly, here we skip the last column of the item, since it is the label\n","                for w in range(len(item)-1):\n","                    self._weights[w] -= self._alpha * (sigma - item[-1]) * (sigma) * (1 - sigma) * item[w]\n","\n","                # Update the sum of squared errors\n","                error += (sigma - item[-1])**2\n","\n","            MSEList[epoch] = error/len(newData)\n","\n","        return MSEList\n","\n","    def classify(self, item):\n","        item = [1] + item\n","\n","        sigma = self._logistic(item)\n","\n","        if (sigma <= self._threshold):\n","            return 0\n","        else:\n","            return 1\n","\n","\n","class StackedGeneralisation():\n","    def __init__(self,classifiers: List[LogisticRegression],aggregator: LogisticRegression):\n","        self.classifiers = classifiers      #Tier-1 classifiers\n","        self.aggregator = aggregator    #Tier-2 meta classifier\n","    \n","    def train(self, dataset:List[list], labels: List[int]):\n","        tier_2_classifer_dataset = []\n","        tier_2_classifier_labels = []\n","        length_dataset = len(dataset)-1\n","        counter = length_dataset\n","        for n in range(len(dataset)):\n","            #STEP 1: Training all classifiers\n","            local_dataset = dataset.copy()  # Copy dataset to modify later     \n","            local_labels = labels.copy()    #Copy labels to modify later\n","            cross_validation_data = local_dataset.pop(counter)  #remove one batch for cross validation\n","            cross_validation_label = local_labels.pop(counter)  \n","            predicted_labels_all = []\n","            for current_classifer in self.classifiers:\n","                current_classifer.train(dataset= local_dataset, labels= local_labels)   #train on remaining data\n","                #STEP 2: Predictions\n","                predicted_label = current_classifer.classify(cross_validation_data)     #get decisions for trained classifier\n","                predicted_labels_all.append(predicted_label)\n","            \n","            counter = 0 if (counter >= length_dataset) else counter+1\n","            # Creating the dataset from Tier-1 decisions for Meta classifier\n","            tier_2_classifer_dataset.append(predicted_labels_all)   #Predicted values from all the classifiers for validation dataset\n","            tier_2_classifier_labels.append(cross_validation_label)     #Expected output for training data in validation dataset\n","        \n","        # STEP 3: Training meta classifier\n","        self.aggregator.train(tier_2_classifer_dataset, tier_2_classifier_labels)\n","        #STEP 4: retrain all classifiers\n","        for current_classifer in self.classifiers:\n","            current_classifer.train(dataset= dataset, labels= labels)\n","        return\n","\n","    def classify(self, item: list): \n","        tier_1_predictions = [] #Store predictions from Tier-1 Classifiers \n","        for current_classifer in self.classifiers:\n","            tier_1_predictions.append(current_classifer.classify(item)) #Get all predictions\n","\n","        sigma = self.aggregator.classify(tier_1_predictions) #get weighted sum of Tier-1 predictions\n","        return 0 if (sigma <= self.aggregator._threshold) else 1   #check applied threshold for classification\n","\n","random.seed(0)\n","dataset = [[0.2,0.4],[0.3,0.7],[0.9,0.7],[0.8,0.9]]\n","labels = [0, 0, 1, 1]\n","\n","classifiers = []\n","classifiers.append(LogisticRegression(2))\n","classifiers.append(LogisticRegression(2,0.3))\n","classifiers.append(LogisticRegression(2,0.3,0.7))\n","classifiers.append(LogisticRegression(2,0.01))\n","classifiers.append(LogisticRegression(2,0.01,0.3))\n","\n","aggregator = LogisticRegression(5)\n","\n","st = StackedGeneralisation(classifiers, aggregator)\n","\n","st.train(dataset, labels)\n","for n in range(len(dataset)):\n","    print(st.classify(dataset[n]), end = \" \")\n","\n","# 0 0 1 1 "],"metadata":{"id":"pNbMnHIeRg1D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rough notes"],"metadata":{"id":"quKd5lRhRhbD"}},{"cell_type":"code","source":["D = [0]*3\n","D = [9,8,7,4]"],"metadata":{"id":"Xvct8YbnDu09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["D.index(8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYkD0dyrcpws","executionInfo":{"status":"ok","timestamp":1646793081039,"user_tz":0,"elapsed":8,"user":{"displayName":"P !","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12288344841493109737"}},"outputId":"14e65fe0-3da6-43d1-e5e9-3add8b8bd8d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["D[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v261SEGjcwHg","executionInfo":{"status":"ok","timestamp":1646793157024,"user_tz":0,"elapsed":199,"user":{"displayName":"P !","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12288344841493109737"}},"outputId":"de375bdd-2ed7-4d1e-8022-e9b32de6b700"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["p_t = [d / sum(D) for d in D]"],"metadata":{"id":"nfEC2XMFEQgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = [[0.2,0.4],[0.3,0.7],[0.9,0.7],[0.8,0.9]]"],"metadata":{"id":"dU8UH6zZEl30"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#dataset.remove([0.8,0.9])\n","d2 = dataset.remove(0)"],"metadata":{"id":"MsuOO3ayM2-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["D = [1.5, 0.5, 1, 0.5]"],"metadata":{"id":"xT_3Cm_lQEaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["newL = list(set(D))"],"metadata":{"id":"5Ug-dmIl6O02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["newL.sort(reverse=True)\n","newL"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Jf95QbB66aq","executionInfo":{"status":"ok","timestamp":1646850431130,"user_tz":0,"elapsed":238,"user":{"displayName":"P !","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12288344841493109737"}},"outputId":"ea163256-aefc-40f8-8ae5-ab042d0ac71c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.5, 1, 0.5]"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["[9,4,5].remove(5)"],"metadata":{"id":"Sum1TPCO7NLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rewards = [[(1,-1),(-1,1)],[(-1,1),(1,-1)]]"],"metadata":{"id":"kuZEVeSX-YSc","executionInfo":{"status":"ok","timestamp":1647010546124,"user_tz":0,"elapsed":12,"user":{"displayName":"P !","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12288344841493109737"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["rewards[1][1][0]"],"metadata":{"id":"1h45hFMfemJK","executionInfo":{"status":"ok","timestamp":1647010556067,"user_tz":0,"elapsed":11,"user":{"displayName":"P !","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12288344841493109737"}},"outputId":"53e30adf-3984-4c4b-c064-d204d4cb598c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":4}]}]}